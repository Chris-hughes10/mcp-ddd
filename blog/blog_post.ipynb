{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4de77ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51ca559",
   "metadata": {},
   "source": [
    "# Building Scalable MCP Servers with Domain-Driven Design\n",
    "\n",
    "AI models are becoming increasingly capable, resulting in a growing need for standardized ways to connect them with our data, tools, and systems. This has become even more pressing with the explosive growth of AI agents - autonomous systems that can understand requests, plan actions, and interact with tools to complete tasks.\n",
    "\n",
    "In the past, integration was often ad-hoc and inconsistent; each application required custom connectors, proprietary interfaces, and duplicated effort. Just as REST APIs standardized how web services communicate, the time has come for a common language for AI models to interact with our digital ecosystem. This is where the Model Context Protocol (MCP) comes in - an open standard that enables LLMs to interact with external resources in a structured, maintainable way.\n",
    "\n",
    "Whether we're building a simple weather lookup tool or a complex enterprise data integration, the architecture patterns we choose will determine how well our MCP servers scale and adapt over time. In this tutorial, we'll explore how to apply [Domain-Driven Design](https://en.wikipedia.org/wiki/Domain-driven_design) principles to build maintainable, scalable MCP servers.\n",
    "\n",
    "> **Note on Code Examples**: The code snippets in this post are simplified for illustration and learning purposes. Complete, runnable implementations with full error handling, logging, and configuration are available in the accompanying repository. Use the repository code as your starting point for real projects.\n",
    "\n",
    "## What is the Model Context Protocol?\n",
    "\n",
    "[The Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction) is an open standard that aims to bring consistency to how applications provide context to Large Language Models (LLMs), providing LLMs with standardized access to external tools and data sources.\n",
    "\n",
    "MCP servers expose three main types of capabilities, each serving different interaction patterns:\n",
    "\n",
    "**Tools** are functions that LLMs can actively call during their reasoning process. They perform computations, trigger actions, and can have side effects. For example, a `get_weather_forecast` tool might fetch real-time data from an API, or a `send_email` tool might trigger an actual email. Tools are discovered by the LLM at runtime, and the model decides when and how to invoke them based on the conversation context.\n",
    "\n",
    "**Resources** provide read-only access to data that can be loaded into the LLM's context. Unlike tools, resources are primarily informational and don't perform actions. Examples could include `file://documents/report.pdf` or `database://customers/recent_orders`. Resources can be static (fixed URIs) or dynamic (parameterized templates like `user://{user_id}/profile`). They're typically loaded by client applications rather than being called directly by the model.\n",
    "\n",
    "**Prompts** are reusable templates that help users initiate specific types of conversations or workflows. They can accept parameters and return structured prompt content. For instance, a `code_review_prompt` might take a programming language and code snippet as parameters, then return a formatted prompt that guides the LLM to perform a thorough code review.\n",
    "\n",
    "When we build an MCP server, we're creating a bridge between an LLM and our specific data or functionality. For example, an LLM can use these tools to check the weather, search company documents, or analyse data - all without having these capabilities built directly into the model during training; all the model needs to know is how to use tools and resources. The beauty of MCP is its standardization - once we build a tool following the protocol, it can be used by any MCP-compatible client.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c610b986",
   "metadata": {},
   "source": [
    "## Building Our First MCP Server\n",
    "\n",
    "Let's start with a practical example to understand MCP in action. We'll build a simple weather MCP server inspired by the official [MCP quickstart guide](https://modelcontextprotocol.io/quickstart/server), then gradually improve it using enterprise-grade architectural patterns.\n",
    "\n",
    "Here's a basic weather server that exposes two tools for getting weather information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35080267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import logging\n",
      "from typing import Any\n",
      "\n",
      "import httpx\n",
      "from mcp.server.fastmcp import FastMCP\n",
      "\n",
      "logging.basicConfig(level=logging.DEBUG)\n",
      "# Initialize FastMCP server\n",
      "mcp = FastMCP(\"weather\")\n",
      "\n",
      "# Constants\n",
      "NWS_API_BASE = \"https://api.weather.gov\"\n",
      "USER_AGENT = \"weather-app/1.0\"\n",
      "\n",
      "\n",
      "async def make_nws_request(url: str) -> dict[str, Any] | None:\n",
      "    \"\"\"Make a request to the NWS API with proper error handling.\"\"\"\n",
      "    headers = {\"User-Agent\": USER_AGENT, \"Accept\": \"application/geo+json\"}\n",
      "    async with httpx.AsyncClient() as client:\n",
      "        try:\n",
      "            response = await client.get(url, headers=headers, timeout=30.0)\n",
      "            response.raise_for_status()\n",
      "            return response.json()\n",
      "        except Exception:\n",
      "            return None\n",
      "\n",
      "\n",
      "def format_alert(feature: dict) -> str:\n",
      "    \"\"\"Format an alert feature into a readable string.\"\"\"\n",
      "    props = feature[\"properties\"]\n",
      "    return f\"\"\"\n",
      "Event: {props.get(\"event\", \"Unknown\")}\n",
      "Area: {props.get(\"areaDesc\", \"Unknown\")}\n",
      "Severity: {props.get(\"severity\", \"Unknown\")}\n",
      "Description: {props.get(\"description\", \"No description available\")}\n",
      "Instructions: {props.get(\"instruction\", \"No specific instructions provided\")}\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "@mcp.tool()\n",
      "async def get_alerts(state: str) -> str:\n",
      "    \"\"\"Get weather alerts for a US state.\n",
      "\n",
      "    Args:\n",
      "        state: Two-letter US state code (e.g. CA, NY)\n",
      "    \"\"\"\n",
      "    url = f\"{NWS_API_BASE}/alerts/active/area/{state}\"\n",
      "    data = await make_nws_request(url)\n",
      "\n",
      "    if not data or \"features\" not in data:\n",
      "        return \"Unable to fetch alerts or no alerts found.\"\n",
      "\n",
      "    if not data[\"features\"]:\n",
      "        return \"No active alerts for this state.\"\n",
      "\n",
      "    alerts = [format_alert(feature) for feature in data[\"features\"]]\n",
      "    return \"\\n---\\n\".join(alerts)\n",
      "\n",
      "\n",
      "@mcp.tool()\n",
      "async def get_forecast(latitude: float, longitude: float) -> str:\n",
      "    \"\"\"Get weather forecast for a location.\n",
      "\n",
      "    Args:\n",
      "        latitude: Latitude of the location\n",
      "        longitude: Longitude of the location\n",
      "    \"\"\"\n",
      "    # First get the forecast grid endpoint\n",
      "    points_url = f\"{NWS_API_BASE}/points/{latitude},{longitude}\"\n",
      "    points_data = await make_nws_request(points_url)\n",
      "\n",
      "    if not points_data:\n",
      "        return \"Unable to fetch forecast data for this location.\"\n",
      "\n",
      "    # Get the forecast URL from the points response\n",
      "    forecast_url = points_data[\"properties\"][\"forecast\"]\n",
      "    forecast_data = await make_nws_request(forecast_url)\n",
      "\n",
      "    if not forecast_data:\n",
      "        return \"Unable to fetch detailed forecast.\"\n",
      "\n",
      "    # Format the periods into a readable forecast\n",
      "    periods = forecast_data[\"properties\"][\"periods\"]\n",
      "    forecasts = []\n",
      "    for period in periods[:5]:  # Only show next 5 periods\n",
      "        forecast = f\"\"\"\n",
      "{period[\"name\"]}:\n",
      "Temperature: {period[\"temperature\"]}°{period[\"temperatureUnit\"]}\n",
      "Wind: {period[\"windSpeed\"]} {period[\"windDirection\"]}\n",
      "Forecast: {period[\"detailedForecast\"]}\n",
      "\"\"\"\n",
      "        forecasts.append(forecast)\n",
      "\n",
      "    return \"\\n---\\n\".join(forecasts)\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    print(\"starting weather server\")\n",
      "    # Initialize and run the server\n",
      "    mcp.run(transport=\"stdio\")\n"
     ]
    }
   ],
   "source": [
    "!cat ../src/servers/simple_weather/weather.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845b6f61",
   "metadata": {},
   "source": [
    "This implementation works and provides useful weather functionality to LLMs. You can run it and connect through MCP clients to get real weather data. But as we examine the code more closely, several architectural issues become apparent:\n",
    "\n",
    "**Mixed Responsibilities**: In the `get_alerts` function, business logic is directly coupled with MCP infrastructure. In just 15 lines, it's handling:\n",
    "- URL construction for external APIs\n",
    "- HTTP communication and error handling  \n",
    "- JSON parsing and data extraction\n",
    "- Business logic (what constitutes an alert)\n",
    "- Response formatting for LLM consumption\n",
    "- MCP protocol concerns (the `@mcp.tool()` decorator)\n",
    "\n",
    "**Testing Challenges**: How would you test the alert formatting logic? Currently, you'd need to either:\n",
    "- Make real HTTP calls to the NWS API (slow, unreliable, requires internet)\n",
    "- Mock the entire `httpx` library (complex setup, brittle tests)\n",
    "- Test everything together as an integration test (hard to isolate failures)\n",
    "\n",
    "**No Domain Model**: We're working directly with raw dictionaries from the API response. When you see `props.get(\"event\", \"Unknown\")`, what business rule does that represent? What happens if the API changes its response format?\n",
    "\n",
    "**Inflexible Infrastructure**: The HTTP client is hard-coded into our business logic. What if we need to add:\n",
    "- Authentication headers for a different weather service?\n",
    "- Retry logic for rate limiting?\n",
    "- Caching to avoid redundant API calls?\n",
    "- Different timeout settings for different endpoints?\n",
    "\n",
    "**Limited Reusability**: This code is tightly coupled to MCP. If you wanted to expose the same weather functionality through a REST API, CLI tool, or GraphQL endpoint, you'd need to duplicate all the business logic.\n",
    "\n",
    "Additionally, we're losing the semantic richness of our domain. When the code processes this API response:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"properties\": {\n",
    "    \"event\": \"Heat Advisory\",\n",
    "    \"severity\": \"Moderate\", \n",
    "    \"areaDesc\": \"Harris County\",\n",
    "    \"description\": \"Heat index values up to 108 degrees...\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "We immediately flatten it into a string for display. We lose the ability to:\n",
    "- Reason about alert severity levels\n",
    "- Group alerts by geographic area  \n",
    "- Store historical alert data for analysis\n",
    "- Apply business rules based on alert types\n",
    "\n",
    "These aren't just theoretical concerns - they become real limitations as requirements evolve. What happens when someone asks for \"severe weather alerts only\" or \"alerts from the past week\"?\n",
    "\n",
    "### When Does This Matter?\n",
    "\n",
    "For simple scripts, proof-of-concepts, or single-purpose tools, the straightforward approach shown above may be the best solution in terms of simplicity, ease of understanding and maintenance. If you're building a quick weather lookup for personal use or a prototype to demonstrate an idea, the additional complexity of Domain-Driven Design probably isn't justified.\n",
    "\n",
    "However, DDD's benefits emerge when building systems that need to handle:\n",
    "- **Changing requirements**: \"Now we need to support multiple weather providers\"\n",
    "- **Complex business rules**: \"Only show severe alerts during business hours\"\n",
    "- **Integration across interfaces**: The same logic needs to work in REST APIs, CLIs, and MCP servers\n",
    "- **Long-term maintenance**: The system will be modified and extended over months or years\n",
    "- **Multiple team members**: Other developers need to understand and modify the code\n",
    "\n",
    "The patterns we'll explore next become valuable when your system needs to evolve and adapt over time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586217fb",
   "metadata": {},
   "source": [
    "## Domain-Driven Design: A Foundation for LLM Interactions\n",
    "\n",
    "Now that we've seen the limitations of the simple approach, let's explore how Domain-Driven Design can address these problems. \n",
    "\n",
    "In the past, I've applied Domain-Driven Design principles to web servers with great success, and when I first encountered the Model Context Protocol, I immediately saw how these same patterns could apply. DDD isn't just another architectural pattern — it's a way of thinking about software that puts our business domain at the centre. Instead of organizing code by technical concerns (controllers, models, views), DDD organizes it by business capabilities (weather forecasting, order processing, user management).\n",
    "\n",
    "This domain-centric approach is even more critical when working with LLMs than with traditional software. Since LLMs operate primarily through understanding context and semantics, having clearly defined domain concepts directly improves their ability to select and use the right tools appropriately. When our MCP servers are built around well-modelled domains with a consistent ubiquitous language, we provide LLMs with the precise context they need to interpret requests correctly and choose the appropriate tools, resources, or prompts.\n",
    "\n",
    "### Understanding the Weather Domain\n",
    "\n",
    "Before writing any code, DDD encourages us to understand the domain we're working in. In weather forecasting, we have concepts like:\n",
    "\n",
    "- **Forecasts**: Complete weather predictions for specific locations\n",
    "- **Periods**: Time segments within a forecast (like \"Tonight\" or \"Tuesday\")  \n",
    "- **Alerts**: Official warnings about dangerous weather conditions that were active at a specific time and location\n",
    "\n",
    "These aren't just data structures - they're meaningful concepts in our domain. When we model our software using this domain language, several things happen:\n",
    "\n",
    "**LLMs Understand Better**: When an LLM sees a function called `get_severe_alerts()`, it immediately understands this will return serious weather threats. A function called `execute_query_for_weather_data_endpoint_with_severity_filter()` requires parsing technical jargon to understand the business purpose.\n",
    "\n",
    "**Code Becomes Self-Documenting**: When you see `alert.severity == \"Extreme\"` in code, you immediately know this is handling the most serious weather threats. Raw dictionary access like `data[\"properties\"][\"severity\"] == \"Extreme\"` buries this business meaning in implementation details.\n",
    "\n",
    "**Requirements Are Clearer**: Stakeholders can say \"We need to track severe alerts over time\" instead of \"We need to store API responses with severity properties in a database table.\"\n",
    "\n",
    "\n",
    "The concept of a **ubiquitous language** - a common vocabulary shared between domain experts and developers - is central to DDD. In an MCP context, this language becomes the bridge between human intent, LLM understanding, and system capabilities.\n",
    "\n",
    "\n",
    "### DDD Building Blocks for Our Weather Domain\n",
    "\n",
    "Let's recap some DDD concepts, and apply these to our weather domain:\n",
    "\n",
    "**Value Objects** represent domain concepts without identity. Our `WeatherPeriod` (temperature, wind, forecast text) and `Coordinate` (latitude, longitude) are perfect examples. Two weather periods with the same data are effectively identical.\n",
    "\n",
    "**Entities** have unique identity that persists over time. While our simple example doesn't need entities, a more complex system might have `WeatherStation` entities with unique identifiers and changing conditions.\n",
    "\n",
    "**Domain Services** encapsulate business logic that doesn't naturally belong in entities or value objects. A `WeatherService` may be defined to contain the business rules for retrieving and formatting weather data - this maps perfectly to MCP tools.\n",
    "\n",
    "**Repositories** provide collection-like interfaces for accessing domain objects. A `WeatherAlertRepository` could be used find alerts by region and time range without exposing whether they're stored in files, databases, or memory.\n",
    "\n",
    "**Application Services** orchestrate domain objects to fulfill specific use cases while staying independent of infrastructure concerns. We could use a `WeatherMCPService` to coordinate domain services and repositories while handling MCP protocol requirements.\n",
    "\n",
    "\n",
    "### The Root Problem: Infrastructure Leaking Into Domain Logic\n",
    "\n",
    "Looking back at our simple weather server, the core issue is that infrastructure concerns have leaked into business logic. The `get_alerts` function doesn't just handle the business concept of \"getting weather alerts\" - it's also responsible for HTTP communication, JSON parsing, error handling, and response formatting.\n",
    "\n",
    "This mixing of concerns makes the code:\n",
    "- **Hard to test**: You can't verify alert logic without HTTP calls\n",
    "- **Difficult to change**: Switching APIs requires changing business logic  \n",
    "- **Impossible to reuse**: The weather logic only works within MCP\n",
    "- **Hard to understand**: Business rules are buried in infrastructure code\n",
    "\n",
    "DDD gives us patterns to separate these concerns cleanly, making our code more maintainable, testable, and adaptable to changing requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c689176b",
   "metadata": {},
   "source": [
    "## The Refactored Domain-Driven Implementation\n",
    "Let's refactor our weather server using DDD principles. We'll build it layer by layer, showing how each piece contributes to a more maintainable architecture.\n",
    "\n",
    "### Domain Models: Speaking the Weather Language\n",
    "\n",
    "First, we create domain models that represent weather concepts using language that domain experts would recognize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1325e0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import datetime\n",
      "from dataclasses import dataclass\n",
      "from typing import List, Optional\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class WeatherPeriod:\n",
      "    \"\"\"Represents a single period in a weather forecast.\n",
      "\n",
      "    A weather period typically corresponds to a 12-hour timeframe\n",
      "    (e.g., \"Tuesday Night\", \"Wednesday\") and contains the core\n",
      "    meteorological data for that period.\n",
      "\n",
      "    Attributes:\n",
      "        name: Human-readable period name (e.g., \"Tonight\", \"Tuesday\")\n",
      "        temperature: Temperature value in the specified unit\n",
      "        temperature_unit: Temperature unit (\"F\" for Fahrenheit, \"C\" for Celsius)\n",
      "        wind_speed: Wind speed description (e.g., \"5 to 10 mph\")\n",
      "        wind_direction: Wind direction abbreviation (e.g., \"NW\", \"SSE\")\n",
      "        detailed_forecast: Complete narrative forecast for this period\n",
      "    \"\"\"\n",
      "\n",
      "    name: str\n",
      "    temperature: float\n",
      "    temperature_unit: str\n",
      "    wind_speed: str\n",
      "    wind_direction: str\n",
      "    detailed_forecast: str\n",
      "\n",
      "    def to_display_string(self) -> str:\n",
      "        \"\"\"Format for human-readable display\"\"\"\n",
      "        return f\"{self.name}: {self.temperature}°{self.temperature_unit} - {self.detailed_forecast}\"\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class Forecast:\n",
      "    \"\"\"Weather forecast aggregate containing multiple time periods.\n",
      "\n",
      "    Represents a complete weather forecast for a location, typically\n",
      "    covering the next 5-7 periods (2-3 days). Follows DDD aggregate\n",
      "    pattern where Forecast is the aggregate root.\n",
      "\n",
      "    Attributes:\n",
      "        periods: List of forecast periods, ordered chronologically\n",
      "        error: Error message if forecast retrieval failed, None if successful\n",
      "        latitude: Location latitude in decimal degrees\n",
      "        longitude: Location longitude in decimal degrees\n",
      "        retrieved_at: UTC timestamp when forecast was fetched\n",
      "    \"\"\"\n",
      "\n",
      "    periods: List[WeatherPeriod]\n",
      "    error: str\n",
      "    latitude: float\n",
      "    longitude: float\n",
      "    retrieved_at: datetime.datetime = None\n",
      "\n",
      "    def to_display_string(self) -> str:\n",
      "        \"\"\"Format for human-readable display\"\"\"\n",
      "        if not self.periods:\n",
      "            return f\"Error: {self.error or 'No forecast data available'}\"\n",
      "\n",
      "        return (\n",
      "            f\"Forecast retrieved at: {self.retrieved_at.strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\"\n",
      "            + f\"\\nLocation: {self.latitude:.4f}, {self.longitude:.4f}\"\n",
      "            + \"\\n\".join(period.to_display_string() for period in self.periods)\n",
      "        )\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class WeatherAlert:\n",
      "    \"\"\"Individual weather alert issued by meteorological authorities.\n",
      "\n",
      "    Represents a single weather warning, watch, or advisory (e.g., tornado\n",
      "    warning, flood watch, heat advisory). Alerts are value objects in DDD\n",
      "    terms - they're identified by their content rather than a unique ID.\n",
      "\n",
      "    Attributes:\n",
      "        event: Alert type/category (e.g., \"Tornado Warning\", \"Heat Advisory\")\n",
      "        area: Geographic description of affected area (e.g., \"Harris County, TX\")\n",
      "        severity: Alert severity level (\"Minor\", \"Moderate\", \"Severe\", \"Extreme\")\n",
      "        description: Full alert description with details and impacts\n",
      "        instructions: Safety instructions for the public (None if not provided)\n",
      "    \"\"\"\n",
      "\n",
      "    event: str\n",
      "    area: str\n",
      "    severity: str\n",
      "    description: str\n",
      "    instructions: Optional[str] = None\n",
      "\n",
      "    def to_display_string(self) -> str:\n",
      "        \"\"\"Format alert for display\"\"\"\n",
      "        result = f\"Event: {self.event}\\nArea: {self.area}\\nSeverity: {self.severity}\"\n",
      "        result += f\"\\nDescription: {self.description}\"\n",
      "\n",
      "        if self.instructions:\n",
      "            result += f\"\\nInstructions: {self.instructions}\"\n",
      "\n",
      "        return result\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class AlertSnapshot:\n",
      "    \"\"\"Collection of weather alerts for a specific area and time.\n",
      "\n",
      "    Aggregate root for weather alerts, grouping related alerts that were\n",
      "    active for a geographic area at a specific point in time. This allows\n",
      "    tracking alert history and provides context for alert analysis.\n",
      "\n",
      "    In DDD terms, this is an aggregate that ensures consistency across\n",
      "    related alerts and provides a clear boundary for persistence operations.\n",
      "\n",
      "    Attributes:\n",
      "        alerts: List of individual weather alerts active at retrieval time\n",
      "        retrieved_at: UTC timestamp when alerts were fetched from service\n",
      "        state: Two-letter US state code for geographic grouping\n",
      "\n",
      "    Business Rules:\n",
      "        - AlertSnapshot represents alerts at a point in time (immutable snapshot)\n",
      "        - Empty alerts list indicates no active alerts (not an error condition)\n",
      "        - State code used for geographic partitioning in storage\n",
      "    \"\"\"\n",
      "\n",
      "    alerts: List[WeatherAlert]\n",
      "    retrieved_at: datetime.datetime\n",
      "    state: str\n",
      "\n",
      "    def to_display_string(self) -> str:\n",
      "        \"\"\"Format alert set for display\"\"\"\n",
      "        if not self.alerts:\n",
      "            return f\"No active alerts for {self.state} at {self.retrieved_at.strftime('%Y-%m-%d %H:%M:%S')}\"\n",
      "\n",
      "        result = f\"Alerts for {self.state} at {self.retrieved_at.strftime('%Y-%m-%d %H:%M:%S')}:\\n\"\n",
      "        result += f\"Found {len(self.alerts)} active alert(s)\\n\\n\"\n",
      "\n",
      "        return result + \"\\n---\\n\".join(\n",
      "            alert.to_display_string() for alert in self.alerts\n",
      "        )\n"
     ]
    }
   ],
   "source": [
    "!cat ../src/servers/weather_service/domain/models.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cf625b",
   "metadata": {},
   "source": [
    "Notice how these models use the vocabulary of the weather domain. Terms like \"forecast\", \"period\", \"alert\", and \"severity\" are immediately meaningful to both weather experts and LLMs. Our **ubiquitous language** creates shared understanding across all parts of our system.\n",
    "\n",
    "The models also include display formatting methods. This follows DDD principles by keeping presentation logic close to the domain objects that know how to represent themselves.\n",
    "\n",
    "### Domain Services: Encapsulating Weather Intelligence\n",
    "\n",
    "Next, let's create a domain service that encapsulates our weather-related business logic; we can define an abstract interface that expresses what our domain can do, independent of how it's implemented:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5272d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from abc import ABC, abstractmethod\n",
      "from typing import List\n",
      "\n",
      "from servers.weather_service.domain.models import Forecast, WeatherAlert\n",
      "\n",
      "\n",
      "class WeatherService(ABC):\n",
      "    \"\"\"Abstract interface for weather data retrieval services.\n",
      "\n",
      "    Defines the domain contract for weather operations. Implementations\n",
      "    should handle external API communication while maintaining domain\n",
      "    model consistency.\n",
      "\n",
      "    This follows the DDD domain service pattern for operations that\n",
      "    don't naturally belong to a single entity or value object.\n",
      "    \"\"\"\n",
      "\n",
      "    @abstractmethod\n",
      "    async def get_forecast(self, latitude: float, longitude: float) -> Forecast:\n",
      "        \"\"\"Retrieve weather forecast for geographic coordinates.\n",
      "\n",
      "        Args:\n",
      "            latitude: Latitude in decimal degrees, range [-90, 90]\n",
      "            longitude: Longitude in decimal degrees, range [-180, 180]\n",
      "\n",
      "        Returns:\n",
      "            Forecast aggregate with periods and metadata\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    @abstractmethod\n",
      "    async def get_alerts(self, state: str) -> List[WeatherAlert]:\n",
      "        \"\"\"Retrieve active weather alerts for a US state.\n",
      "\n",
      "        Args:\n",
      "            state: Two-letter US state code (e.g., \"CA\", \"TX\", \"FL\")\n",
      "                Must be normalized to uppercase by implementations\n",
      "                Invalid state codes should return empty list, not error\n",
      "\n",
      "        Returns:\n",
      "            List of WeatherAlert domain objects representing all currently\n",
      "            active alerts for the specified state. Empty list indicates no\n",
      "            active alerts (normal condition, not an error).\n",
      "        \"\"\"\n",
      "        pass\n"
     ]
    }
   ],
   "source": [
    "!cat ../src/servers/weather_service/domain/service/interfaces.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e80f02",
   "metadata": {},
   "source": [
    "### Abstract Interfaces: Domain Focus and LLM-Friendly Code Generation\n",
    "\n",
    "This abstract interface serves multiple purposes beyond traditional software engineering benefits. By keeping the interface focused purely on domain concepts—forecasts, alerts, coordinates, states—we create a clear contract that isolates business logic from technical implementation details.\n",
    "\n",
    "This domain-focused design has an unexpected modern benefit: it significantly improves LLM-assisted code generation. When an LLM sees a well-defined interface like `WeatherService`, it understands exactly what needs to be implemented:\n",
    "\n",
    "```python\n",
    "# Example LLM prompt: \"Implement a mock WeatherService for testing\"\n",
    "class MockWeatherService(WeatherService):\n",
    "    \"\"\"The LLM knows exactly what methods to implement and their signatures\"\"\"\n",
    "    async def get_forecast(self, latitude: float, longitude: float) -> Forecast:\n",
    "        # LLM generates appropriate mock data with correct types\n",
    "        return Forecast(\n",
    "            periods=[WeatherPeriod(name=\"Test\", temperature=72.0, ...)],\n",
    "            error=None,\n",
    "            latitude=latitude,\n",
    "            longitude=longitude,\n",
    "            retrieved_at=datetime.now()\n",
    "        )\n",
    "```\n",
    "\n",
    "The constrained interface guides the LLM to generate implementations that follow our domain model, use the correct types, and maintain business logic separation. This makes AI-assisted development much more reliable than working with loosely-defined functions or mixed-responsibility classes.\n",
    "\n",
    "This interface is crucial because it expresses our domain capabilities without binding us to any specific implementation. We can create an NWS implementation, a mock implementation for testing, or even a composite implementation that combines multiple weather services.\n",
    "\n",
    "The concrete implementation focuses solely on translating between the external API and our domain models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21181c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import datetime\n",
      "from typing import Any, Dict, List\n",
      "\n",
      "from servers.weather_service.domain.models import Forecast, WeatherAlert, WeatherPeriod\n",
      "from servers.weather_service.domain.service.interfaces import WeatherService\n",
      "from servers.weather_service.infrastructure.adaptors import make_request\n",
      "\n",
      "\n",
      "class NWSWeatherService(WeatherService):\n",
      "    \"\"\"National Weather Service implementation of WeatherService.\n",
      "\n",
      "    Integrates with the NWS API (weather.gov) which provides free\n",
      "    weather data for US locations. Uses the two-step process:\n",
      "    1. GET /points/{lat},{lon} to get forecast endpoint\n",
      "    2. GET forecast endpoint to retrieve actual forecast data\n",
      "\n",
      "    Args:\n",
      "        make_http_request: HTTP client function for dependency injection\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, make_http_request=make_request):\n",
      "        self.get = make_http_request\n",
      "        self.base_url = \"https://api.weather.gov\"\n",
      "        self.headers = {\n",
      "            \"User-Agent\": \"weather-app/1.0\",\n",
      "            \"Accept\": \"application/geo+json\",\n",
      "        }\n",
      "\n",
      "    async def get_forecast(self, latitude: float, longitude: float) -> Forecast:\n",
      "        \"\"\"Get weather forecast for a location.\n",
      "\n",
      "        Args:\n",
      "            latitude: Latitude of the location\n",
      "            longitude: Longitude of the location\n",
      "        \"\"\"\n",
      "        # First get the forecast grid endpoint\n",
      "        points_url = f\"{self.base_url}/points/{latitude},{longitude}\"\n",
      "        request_time = datetime.datetime.now()\n",
      "        points_data = await self.get(points_url, headers=self.headers)\n",
      "\n",
      "        if not points_data:\n",
      "            return Forecast(\n",
      "                periods=[],\n",
      "                error=\"Unable to fetch forecast data for this location.\",\n",
      "                retrieved_at=request_time,\n",
      "                latitude=latitude,\n",
      "                longitude=longitude,\n",
      "            )\n",
      "\n",
      "        # Get the forecast URL from the points response\n",
      "        forecast_url = points_data[\"properties\"][\"forecast\"]\n",
      "        forecast_data = await self.get(forecast_url, headers=self.headers)\n",
      "\n",
      "        if not forecast_data:\n",
      "            return Forecast(\n",
      "                periods=[],\n",
      "                error=\"Unable to fetch detailed forecast.\",\n",
      "                retrieved_at=request_time,\n",
      "                latitude=latitude,\n",
      "                longitude=longitude,\n",
      "            )\n",
      "\n",
      "        # Convert API data to Domain objects\n",
      "        periods = []\n",
      "        for period in forecast_data[\"properties\"][\"periods\"][:5]:\n",
      "            periods.append(\n",
      "                WeatherPeriod(\n",
      "                    name=period[\"name\"],\n",
      "                    temperature=period[\"temperature\"],\n",
      "                    temperature_unit=period[\"temperatureUnit\"],\n",
      "                    wind_speed=period[\"windSpeed\"],\n",
      "                    wind_direction=period[\"windDirection\"],\n",
      "                    detailed_forecast=period[\"detailedForecast\"],\n",
      "                )\n",
      "            )\n",
      "\n",
      "        return Forecast(\n",
      "            periods=periods,\n",
      "            error=None,\n",
      "            retrieved_at=request_time,\n",
      "            latitude=latitude,\n",
      "            longitude=longitude,\n",
      "        )\n",
      "\n",
      "    async def get_alerts(self, state: str) -> List[WeatherAlert]:\n",
      "        \"\"\"Get weather alerts for a US state.\n",
      "\n",
      "        Args:\n",
      "            state: Two-letter US state code (e.g. CA, NY)\n",
      "        \"\"\"\n",
      "        data = await self.get(\n",
      "            f\"{self.base_url}/alerts/active/area/{state}\", headers=self.headers\n",
      "        )\n",
      "\n",
      "        if not data or \"features\" not in data:\n",
      "            return []  # \"Unable to fetch alerts or no alerts found.\"\n",
      "\n",
      "        if not data[\"features\"]:\n",
      "            return []  # \"No active alerts for this state.\"\n",
      "\n",
      "        alerts = []\n",
      "        for feature in data[\"features\"]:\n",
      "            props = feature[\"properties\"]\n",
      "            alerts.append(\n",
      "                WeatherAlert(\n",
      "                    event=props.get(\"event\", \"Unknown\"),\n",
      "                    area=props.get(\"areaDesc\", \"Unknown\"),\n",
      "                    severity=props.get(\"severity\", \"Unknown\"),\n",
      "                    description=props.get(\"description\", \"No description available\"),\n",
      "                    instructions=props.get(\"instruction\"),\n",
      "                )\n",
      "            )\n",
      "\n",
      "        return alerts\n"
     ]
    }
   ],
   "source": [
    "!cat ../src/servers/weather_service/domain/service/services.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a60c5c1",
   "metadata": {},
   "source": [
    "### Infrastructure Separation: Keeping External Concerns at the Boundary\n",
    "\n",
    "Notice how we've isolated HTTP communication in the infrastructure layer by injecting the `make_http_request` function:\n",
    "\n",
    "```python\n",
    "# infrastructure/adaptors.py\n",
    "async def make_request(url: str, headers: Dict[str, str] = None) -> Dict[str, Any]:\n",
    "    \"\"\"HTTP client adapter for external API calls.\"\"\"\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        try:\n",
    "            response = await client.get(url, headers=headers, timeout=30.0)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except Exception:\n",
    "            return None  # Simplified error handling\n",
    "```\n",
    "\n",
    "This separation is a key DDD principle - infrastructure concerns like HTTP clients, database connections, or file I/O should be isolated from domain logic. This provides several benefits:\n",
    "\n",
    "**Testing Flexibility**: We can inject a stub HTTP client for unit tests:\n",
    "\n",
    "```python\n",
    "# In tests - using a STUB to return hardcoded responses\n",
    "async def http_stub(url, headers=None):\n",
    "    if \"points\" in url:\n",
    "        return {\"properties\": {\"forecast\": \"https://api.weather.gov/forecast/...\"}}\n",
    "    elif \"forecast\" in url:\n",
    "        return {\"properties\": {\"periods\": [test_period_data]}}\n",
    "    # ... other test cases\n",
    "\n",
    "weather_service = NWSWeatherService(http_stub)\n",
    "forecast = await weather_service.get_forecast(37.7749, -122.4194)\n",
    "# Test domain logic without network calls\n",
    "```\n",
    "\n",
    "**Configuration Management**: We can inject different HTTP clients with different settings:\n",
    "\n",
    "```python\n",
    "# For production - with retries and auth\n",
    "production_client = make_authenticated_request_with_retries\n",
    "\n",
    "# For development - with debug logging  \n",
    "debug_client = make_request_with_logging\n",
    "\n",
    "weather_service = NWSWeatherService(production_client)\n",
    "```\n",
    "\n",
    "### Repository Layer: Abstracting Data Persistence\n",
    "\n",
    "The National Weather Service API provides current conditions but no historical data. To enable trend analysis and provide context for LLM interactions, we need to persist weather information over time. In DDD, repositories provide collection-like interfaces for accessing domain aggregates while abstracting away storage concerns.\n",
    "\n",
    "Let's start by defining what our weather domain needs from data persistence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6074651a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from abc import ABC, abstractmethod\n",
      "from datetime import timedelta\n",
      "from typing import List, Optional, Union\n",
      "\n",
      "from servers.weather_service.domain.models import AlertSnapshot, Forecast, WeatherAlert\n",
      "\n",
      "\n",
      "class WeatherForecastRepository(ABC):\n",
      "    \"\"\"Repository for weather forecast aggregate persistence.\n",
      "\n",
      "    Stores and retrieves complete Forecast aggregates by geographic location\n",
      "    and time. Supports location-based queries and time-windowed filtering\n",
      "    for both current and historical forecast analysis.\n",
      "    \"\"\"\n",
      "\n",
      "    @abstractmethod\n",
      "    async def get_forecasts(\n",
      "        self,\n",
      "        latitude: float,\n",
      "        longitude: float,\n",
      "        time_window: Union[int, timedelta] = 3,\n",
      "        time_unit: str = \"hours\",\n",
      "        limit: Optional[int] = None,\n",
      "    ) -> List[Forecast]:\n",
      "        \"\"\"Find forecasts for a location within a time window.\n",
      "\n",
      "        Args:\n",
      "            latitude: Geographic latitude in decimal degrees\n",
      "            longitude: Geographic longitude in decimal degrees\n",
      "            time_window: How far back to search (int uses time_unit)\n",
      "            time_unit: \"hours\" or \"days\" when time_window is int\n",
      "            limit: Maximum forecasts to return\n",
      "\n",
      "        Returns:\n",
      "            List of complete Forecast aggregates, newest-first\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    @abstractmethod\n",
      "    async def save_forecast(\n",
      "        self, latitude: float, longitude: float, forecast: Forecast\n",
      "    ) -> None:\n",
      "        \"\"\"Save a complete forecast aggregate.\n",
      "\n",
      "        Args:\n",
      "            latitude: Geographic latitude\n",
      "            longitude: Geographic longitude\n",
      "            forecast: Complete Forecast with all periods and metadata\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "\n",
      "class WeatherAlertRepository(ABC):\n",
      "    \"\"\"Repository for weather alert snapshot aggregate persistence.\n",
      "\n",
      "    Manages AlertSnapshot aggregates that capture the complete set of alerts\n",
      "    active for a state at specific points in time. Enables historical alert\n",
      "    pattern analysis and trend monitoring.\n",
      "    \"\"\"\n",
      "\n",
      "    @abstractmethod\n",
      "    async def get_alerts(\n",
      "        self,\n",
      "        state: str,\n",
      "        time_window: Union[int, timedelta] = 24,\n",
      "        time_unit: str = \"hours\",\n",
      "        limit: Optional[int] = None,\n",
      "    ) -> List[AlertSnapshot]:\n",
      "        \"\"\"Find alert sets for a state within a time window\n",
      "\n",
      "        Args:\n",
      "            state: Two-letter US state code\n",
      "            time_window: Number of time units to look back\n",
      "            time_unit: Either \"hours\" or \"days\"\n",
      "            limit: Maximum number of alert sets to return\n",
      "\n",
      "        Returns:\n",
      "            List of alert sets matching criteria, sorted newest first\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    @abstractmethod\n",
      "    async def save_alerts(\n",
      "        self, state: str, alerts: List[WeatherAlert]\n",
      "    ) -> AlertSnapshot:\n",
      "        \"\"\"Save alerts as a new alert set\n",
      "\n",
      "        Args:\n",
      "            state: Two-letter US state code\n",
      "            alerts: List of alerts to save (empty list = no alerts)\n",
      "\n",
      "        Returns:\n",
      "            The created AlertSnapshot\n",
      "        \"\"\"\n",
      "        pass\n"
     ]
    }
   ],
   "source": [
    "!cat ../src/servers/weather_service/domain/repository/interfaces.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042bf1ee",
   "metadata": {},
   "source": [
    "\n",
    "These interfaces express our domain's data needs without committing to any storage technology. We can query forecasts by location and time, alerts by state and time, and persist both types of weather data.\n",
    "\n",
    "### Building Reusable Infrastructure\n",
    "\n",
    "Rather than implementing each repository from scratch, we can identify common patterns and create reusable infrastructure. Our weather data has a common characteristic: everything is timestamped and organized by geographic keys (locations for forecasts, states for alerts).\n",
    "This leads us to a two-layer approach:\n",
    "\n",
    "**Generic Infrastructure** (reusable across any domain):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6b203d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import json\n",
      "from abc import ABC, abstractmethod\n",
      "from collections import deque\n",
      "from datetime import datetime, timedelta\n",
      "from pathlib import Path\n",
      "from typing import Any, Callable, Deque, Dict, Generic, List, Optional, TypeVar, Union\n",
      "\n",
      "\n",
      "class JsonFileRepository(ABC):\n",
      "    \"\"\"Abstract base class for JSON file-based repositories\"\"\"\n",
      "\n",
      "    def __init__(self, file_path: str):\n",
      "        \"\"\"Initialize repository and load existing data\n",
      "\n",
      "        Args:\n",
      "            file_path: Path to the JSON file for persistence\n",
      "        \"\"\"\n",
      "        self.file_path = Path(file_path)\n",
      "        data = self._load_from_file()  # Capture the returned data\n",
      "        self._deserialize_data(data)  # Process the data into collections\n",
      "\n",
      "    def _save_to_file(self, serializable_data: Dict[str, Any]) -> None:\n",
      "        \"\"\"Save data to JSON file\n",
      "\n",
      "        Args:\n",
      "            serializable_data: Dictionary of serialized data to save\n",
      "        \"\"\"\n",
      "        # Create directory if it doesn't exist\n",
      "        self.file_path.parent.mkdir(parents=True, exist_ok=True)\n",
      "\n",
      "        # Write to file\n",
      "        with open(self.file_path, \"w\") as f:\n",
      "            json.dump(serializable_data, f, indent=2)\n",
      "\n",
      "    def _load_from_file(self) -> Dict[str, Any]:\n",
      "        \"\"\"Load data from JSON file if it exists\n",
      "\n",
      "        Returns:\n",
      "            Dictionary of loaded data or empty dict if file doesn't exist\n",
      "        \"\"\"\n",
      "        if not self.file_path.exists():\n",
      "            return {}  # No file to load\n",
      "\n",
      "        try:\n",
      "            with open(self.file_path, \"r\") as f:\n",
      "                loaded_data = json.load(f)\n",
      "                return loaded_data\n",
      "\n",
      "        except (json.JSONDecodeError, IOError) as e:\n",
      "            # Log error but continue with empty repository\n",
      "            print(f\"Error loading data from {self.file_path}: {e}\")\n",
      "            return {}\n",
      "\n",
      "    @abstractmethod\n",
      "    def _serialize_data(self) -> Dict[str, Any]:\n",
      "        \"\"\"Convert in-memory data to serializable dictionary\n",
      "\n",
      "        Returns:\n",
      "            Dictionary representation of the data\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    @abstractmethod\n",
      "    def _deserialize_data(self, data: Dict[str, Any]) -> None:\n",
      "        \"\"\"Load data from serialized dictionary into memory\n",
      "\n",
      "        Args:\n",
      "            data: Serialized data to load\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "\n",
      "# Define generic type variables\n",
      "T = TypeVar(\"T\")  # For domain objects (Forecast, AlertSnapshot)\n",
      "K = TypeVar(\"K\")  # For key types (str for state, str for location)\n",
      "\n",
      "\n",
      "class TimestampedCollectionRepository(JsonFileRepository, Generic[T, K]):\n",
      "    \"\"\"Generic repository for timestamped domain objects with TTL support.\n",
      "\n",
      "    Implements a generic pattern for storing collections of timestamped\n",
      "    objects with automatic expiration and\n",
      "    size limits. Uses the Repository pattern from DDD to abstract\n",
      "    persistence concerns.\n",
      "\n",
      "    Type Parameters:\n",
      "        T: Domain object type (must have timestamp attribute)\n",
      "        K: Key type for grouping objects (str for location keys)\n",
      "\n",
      "    Args:\n",
      "        file_path: JSON file path for persistence\n",
      "        max_items_per_key: Maximum objects to retain per key\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, file_path: str, max_items_per_key: int = 20):\n",
      "        \"\"\"Initialize repository\"\"\"\n",
      "        self.collections: Dict[K, Deque[T]] = {}\n",
      "        self.max_items_per_key = max_items_per_key\n",
      "        super().__init__(file_path)\n",
      "\n",
      "    async def find_items(\n",
      "        self,\n",
      "        key: K,\n",
      "        time_window: Union[int, timedelta] = 24,\n",
      "        time_unit: str = \"hours\",\n",
      "        limit: Optional[int] = None,\n",
      "        timestamp_getter: Callable[[T], datetime] = lambda x: x.retrieved_at,\n",
      "    ) -> List[T]:\n",
      "        \"\"\"Find items within a time window, newest first.\n",
      "\n",
      "        Args:\n",
      "            key: Grouping key (e.g., location identifier)\n",
      "            time_window: How far back to look (int or timedelta)\n",
      "            time_unit: Units for time_window if int (\"hours\" or \"days\")\n",
      "            limit: Maximum items to return (None for no limit)\n",
      "            timestamp_getter: Function to extract timestamp from items\n",
      "\n",
      "        Returns:\n",
      "            List of items matching criteria, ordered newest to oldest\n",
      "        \"\"\"\n",
      "        if key not in self.collections:\n",
      "            return []\n",
      "\n",
      "        # Calculate cutoff time\n",
      "        cutoff_time = self._calculate_cutoff_time(time_window, time_unit)\n",
      "\n",
      "        # Filter items by time\n",
      "        valid_items = [\n",
      "            item\n",
      "            for item in self.collections[key]\n",
      "            if timestamp_getter(item) >= cutoff_time\n",
      "        ]\n",
      "\n",
      "        # Apply limit if specified\n",
      "        if limit is not None and limit > 0:\n",
      "            valid_items = valid_items[:limit]\n",
      "\n",
      "        return valid_items\n",
      "\n",
      "    async def save_item(self, key: K, item: T) -> T:\n",
      "        \"\"\"Save an item under the given key\"\"\"\n",
      "        # Initialize deque if this is the first item for this key\n",
      "        if key not in self.collections:\n",
      "            self.collections[key] = deque(maxlen=self.max_items_per_key)\n",
      "\n",
      "        # Add new item at the beginning (newest first)\n",
      "        self.collections[key].appendleft(item)\n",
      "\n",
      "        # Save to file\n",
      "        self._save_to_file(self._serialize_data())\n",
      "\n",
      "        return item\n",
      "\n",
      "    async def get_most_recent_item(self, key: K) -> Optional[T]:\n",
      "        \"\"\"Get the most recent item for a key\"\"\"\n",
      "        if key not in self.collections or not self.collections[key]:\n",
      "            return None\n",
      "\n",
      "        return self.collections[key][0]  # First item is most recent\n",
      "\n",
      "    def _calculate_cutoff_time(\n",
      "        self, time_window: Union[int, timedelta], time_unit: str\n",
      "    ) -> datetime:\n",
      "        \"\"\"Calculate cutoff time based on window and unit\"\"\"\n",
      "        if isinstance(time_window, timedelta):\n",
      "            return datetime.now() - time_window\n",
      "\n",
      "        if time_unit == \"hours\":\n",
      "            return datetime.now() - timedelta(hours=time_window)\n",
      "        elif time_unit == \"days\":\n",
      "            return datetime.now() - timedelta(days=time_window)\n",
      "        else:\n",
      "            raise ValueError(\n",
      "                f\"Invalid time_unit: {time_unit}, must be 'hours' or 'days'\"\n",
      "            )\n",
      "\n",
      "    def _serialize_data(self) -> Dict[str, Any]:\n",
      "        \"\"\"Convert in-memory collections to serializable dictionary\"\"\"\n",
      "        serializable_data = {}\n",
      "\n",
      "        for key, items in self.collections.items():\n",
      "            # Convert deque to list and serialize each item\n",
      "            serializable_data[str(key)] = [self._serialize_item(item) for item in items]\n",
      "\n",
      "        return serializable_data\n",
      "\n",
      "    def _deserialize_data(self, data: Dict[str, Any]) -> None:\n",
      "        \"\"\"Load data from serialized dictionary into memory\"\"\"\n",
      "        for key_str, items_data in data.items():\n",
      "            key = self._deserialize_key(key_str)\n",
      "            # Create a deque with maxlen for each key\n",
      "            self.collections[key] = deque(\n",
      "                [self._deserialize_item(item) for item in items_data],\n",
      "                maxlen=self.max_items_per_key,\n",
      "            )\n",
      "\n",
      "    @abstractmethod\n",
      "    def _serialize_item(self, item: T) -> Dict[str, Any]:\n",
      "        \"\"\"Convert an item to a serializable dictionary\"\"\"\n",
      "        pass\n",
      "\n",
      "    @abstractmethod\n",
      "    def _deserialize_item(self, data: Dict[str, Any]) -> T:\n",
      "        \"\"\"Create an item from a dictionary\"\"\"\n",
      "        pass\n",
      "\n",
      "    @abstractmethod\n",
      "    def _deserialize_key(self, key_str: str) -> K:\n",
      "        \"\"\"Convert a string key back to the appropriate type\"\"\"\n",
      "        pass\n"
     ]
    }
   ],
   "source": [
    "!cat ../src/servers/weather_service/infrastructure/repositories.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0584122",
   "metadata": {},
   "source": [
    "**Domain-Specific Implementation** (weather business logic):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e08b71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from datetime import datetime, timedelta\n",
      "from typing import Any, Dict, List, Optional, Union\n",
      "\n",
      "from servers.weather_service.domain.models import (\n",
      "    AlertSnapshot,\n",
      "    Forecast,\n",
      "    WeatherAlert,\n",
      "    WeatherPeriod,\n",
      ")\n",
      "from servers.weather_service.domain.repository.interfaces import (\n",
      "    WeatherAlertRepository,\n",
      "    WeatherForecastRepository,\n",
      ")\n",
      "from servers.weather_service.infrastructure.repositories import (\n",
      "    TimestampedCollectionRepository,\n",
      ")\n",
      "\n",
      "\n",
      "class JsonFileWeatherForecastRepository(\n",
      "    TimestampedCollectionRepository[Forecast, str], WeatherForecastRepository\n",
      "):\n",
      "    \"\"\"File-based weather forecast repository using JSON persistence.\n",
      "\n",
      "    Stores forecasts in a local JSON file with automatic rotation and\n",
      "    size limits. Suitable for development, testing, and small deployments.\n",
      "    For production use, consider database-backed implementations.\n",
      "\n",
      "    Args:\n",
      "        file_path: Path to JSON storage file (created if doesn't exist)\n",
      "        max_forecasts_per_location: Maximum forecasts to retain per location\n",
      "            (older forecasts are automatically purged)\n",
      "\n",
      "    File Format:\n",
      "        JSON object with location keys mapping to arrays of forecast objects.\n",
      "        Example: {\"location:40.7128:-74.0060\": [forecast1, forecast2, ...]}\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(\n",
      "        self, file_path: str = \"weather_data.json\", max_forecasts_per_location: int = 10\n",
      "    ):\n",
      "        \"\"\"Initialize repository\"\"\"\n",
      "        super().__init__(file_path, max_forecasts_per_location)\n",
      "\n",
      "    async def get_forecasts(\n",
      "        self,\n",
      "        latitude: float,\n",
      "        longitude: float,\n",
      "        time_window: Union[int, timedelta] = 3,\n",
      "        time_unit: str = \"hours\",\n",
      "        limit: Optional[int] = None,\n",
      "    ) -> List[Forecast]:\n",
      "        \"\"\"Find forecasts for a location within a time window\"\"\"\n",
      "        key = self._make_location_key(latitude, longitude)\n",
      "        return await self.find_items(key, time_window, time_unit, limit)\n",
      "\n",
      "    async def save_forecast(\n",
      "        self, latitude: float, longitude: float, forecast: Forecast\n",
      "    ) -> None:\n",
      "        \"\"\"Save forecast data\"\"\"\n",
      "        # Ensure forecast has location and timestamp data\n",
      "        forecast.latitude = latitude\n",
      "        forecast.longitude = longitude\n",
      "        if not forecast.retrieved_at:\n",
      "            forecast.retrieved_at = datetime.now()\n",
      "\n",
      "        key = self._make_location_key(latitude, longitude)\n",
      "        await self.save_item(key, forecast)\n",
      "\n",
      "    def _make_location_key(self, latitude: float, longitude: float) -> str:\n",
      "        \"\"\"Create a unique key for location\"\"\"\n",
      "        return f\"location:{latitude:.4f}:{longitude:.4f}\"\n",
      "\n",
      "    def _serialize_item(self, forecast: Forecast) -> Dict[str, Any]:\n",
      "        \"\"\"Convert a Forecast to a serializable dictionary\"\"\"\n",
      "        return {\n",
      "            \"periods\": [\n",
      "                self._serialize_weather_period(period) for period in forecast.periods\n",
      "            ],\n",
      "            \"error\": forecast.error,\n",
      "            \"retrieved_at\": forecast.retrieved_at.isoformat()\n",
      "            if forecast.retrieved_at\n",
      "            else None,\n",
      "            \"latitude\": forecast.latitude,\n",
      "            \"longitude\": forecast.longitude,\n",
      "        }\n",
      "\n",
      "    def _deserialize_item(self, data: Dict[str, Any]) -> Forecast:\n",
      "        \"\"\"Create a Forecast from a dictionary\"\"\"\n",
      "        return Forecast(\n",
      "            periods=[\n",
      "                self._deserialize_weather_period(period) for period in data[\"periods\"]\n",
      "            ],\n",
      "            error=data[\"error\"],\n",
      "            retrieved_at=datetime.fromisoformat(data[\"retrieved_at\"])\n",
      "            if data[\"retrieved_at\"]\n",
      "            else None,\n",
      "            latitude=data.get(\"latitude\"),\n",
      "            longitude=data.get(\"longitude\"),\n",
      "        )\n",
      "\n",
      "    def _deserialize_key(self, key_str: str) -> str:\n",
      "        \"\"\"Keys are already strings\"\"\"\n",
      "        return key_str\n",
      "\n",
      "    def _serialize_weather_period(self, period: WeatherPeriod) -> dict:\n",
      "        \"\"\"Convert a WeatherPeriod to a serializable dictionary\"\"\"\n",
      "        return {\n",
      "            \"name\": period.name,\n",
      "            \"temperature\": period.temperature,\n",
      "            \"temperature_unit\": period.temperature_unit,\n",
      "            \"wind_speed\": period.wind_speed,\n",
      "            \"wind_direction\": period.wind_direction,\n",
      "            \"detailed_forecast\": period.detailed_forecast,\n",
      "        }\n",
      "\n",
      "    def _deserialize_weather_period(self, data: dict) -> WeatherPeriod:\n",
      "        \"\"\"Create a WeatherPeriod from a dictionary\"\"\"\n",
      "        return WeatherPeriod(\n",
      "            name=data[\"name\"],\n",
      "            temperature=data[\"temperature\"],\n",
      "            temperature_unit=data[\"temperature_unit\"],\n",
      "            wind_speed=data[\"wind_speed\"],\n",
      "            wind_direction=data[\"wind_direction\"],\n",
      "            detailed_forecast=data[\"detailed_forecast\"],\n",
      "        )\n",
      "\n",
      "\n",
      "class JsonFileWeatherAlertRepository(\n",
      "    TimestampedCollectionRepository[AlertSnapshot, str], WeatherAlertRepository\n",
      "):\n",
      "    \"\"\"Repository for weather alerts using JSON file storage\"\"\"\n",
      "\n",
      "    def __init__(\n",
      "        self, file_path: str = \"weather_alerts.json\", max_sets_per_state: int = 20\n",
      "    ):\n",
      "        \"\"\"Initialize repository\"\"\"\n",
      "        super().__init__(file_path, max_sets_per_state)\n",
      "\n",
      "    async def get_alerts(\n",
      "        self,\n",
      "        state: str,\n",
      "        time_window: Union[int, timedelta] = 24,\n",
      "        time_unit: str = \"hours\",\n",
      "        limit: Optional[int] = None,\n",
      "    ) -> List[AlertSnapshot]:\n",
      "        \"\"\"Find alert sets for a state within a time window\"\"\"\n",
      "        key = self._make_state_key(state)\n",
      "        return await self.find_items(key, time_window, time_unit, limit)\n",
      "\n",
      "    async def save_alerts(\n",
      "        self, state: str, alerts: List[WeatherAlert]\n",
      "    ) -> AlertSnapshot:\n",
      "        \"\"\"Save alerts as a new alert set\"\"\"\n",
      "        # Create new alert set\n",
      "        alert_set = AlertSnapshot(\n",
      "            alerts=alerts, retrieved_at=datetime.now(), state=state.upper()\n",
      "        )\n",
      "\n",
      "        key = self._make_state_key(state)\n",
      "        return await self.save_item(key, alert_set)\n",
      "\n",
      "    def _make_state_key(self, state: str) -> str:\n",
      "        \"\"\"Create a unique key for state\"\"\"\n",
      "        return f\"state:{state.upper()}\"\n",
      "\n",
      "    def _serialize_item(self, alert_set: AlertSnapshot) -> Dict[str, Any]:\n",
      "        \"\"\"Convert an AlertSnapshot to a serializable dictionary\"\"\"\n",
      "        return {\n",
      "            \"state\": alert_set.state,\n",
      "            \"retrieved_at\": alert_set.retrieved_at.isoformat(),\n",
      "            \"alerts\": [self._serialize_alert(alert) for alert in alert_set.alerts],\n",
      "        }\n",
      "\n",
      "    def _deserialize_item(self, data: Dict[str, Any]) -> AlertSnapshot:\n",
      "        \"\"\"Create an AlertSnapshot from a dictionary\"\"\"\n",
      "        return AlertSnapshot(\n",
      "            state=data[\"state\"],\n",
      "            retrieved_at=datetime.fromisoformat(data[\"retrieved_at\"]),\n",
      "            alerts=[\n",
      "                self._deserialize_alert(alert_data) for alert_data in data[\"alerts\"]\n",
      "            ],\n",
      "        )\n",
      "\n",
      "    def _deserialize_key(self, key_str: str) -> str:\n",
      "        \"\"\"Keys are already strings\"\"\"\n",
      "        return key_str\n",
      "\n",
      "    def _serialize_alert(self, alert: WeatherAlert) -> dict:\n",
      "        \"\"\"Convert a WeatherAlert to a serializable dictionary\"\"\"\n",
      "        return {\n",
      "            \"event\": alert.event,\n",
      "            \"area\": alert.area,\n",
      "            \"severity\": alert.severity,\n",
      "            \"description\": alert.description,\n",
      "            \"instructions\": alert.instructions,\n",
      "        }\n",
      "\n",
      "    def _deserialize_alert(self, data: dict) -> WeatherAlert:\n",
      "        \"\"\"Create a WeatherAlert from a dictionary\"\"\"\n",
      "        return WeatherAlert(\n",
      "            event=data[\"event\"],\n",
      "            area=data[\"area\"],\n",
      "            severity=data[\"severity\"],\n",
      "            description=data[\"description\"],\n",
      "            instructions=data.get(\"instructions\"),\n",
      "        )\n"
     ]
    }
   ],
   "source": [
    "!cat ../src/servers/weather_service/domain/repository/repositories.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a031cb53",
   "metadata": {},
   "source": [
    "\n",
    " In our implementation, domain repository implementations live in the domain layer (`domain/repository/repositories.py`) rather than the infrastructure layer. This follows the principle that these implementations contain weather-specific business logic—how to construct location keys, what time windows make sense for weather data, how to serialize weather concepts.\n",
    "\n",
    "The infrastructure layer (`infrastructure/repositories.py`) contains the generic, reusable patterns that any domain could use. This separation ensures our domain repositories are focused on weather concepts while leveraging proven technical patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1942fd4c",
   "metadata": {},
   "source": [
    "### Why This Layered Approach Works\n",
    "\n",
    "This separation provides several key benefits:\n",
    "\n",
    "**Domain Focus**: The weather repositories contain only weather-specific logic - how to construct location keys from coordinates, how to serialize weather data, what time windows make sense for forecasts vs. alerts.\n",
    "\n",
    "**Reusability**: The `TimestampedCollectionRepository` can be used by any domain that needs time-based data storage - user activity logs, financial transactions, system events, etc.\n",
    "\n",
    "**Testing Clarity**: We can test the generic infrastructure separately from domain-specific behavior, making failures easier to diagnose and fix.\n",
    "\n",
    "**Technology Independence**: If we wanted to switch from JSON files to Redis, we'd only need to change the infrastructure layer. The domain-specific logic about forecasts and alerts remains unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2f207a",
   "metadata": {},
   "source": [
    "### Application Service: Orchestrating the Domain\n",
    "\n",
    "Now that we have domain services for weather operations and repositories for data persistence, we need something to coordinate these components and expose them through the MCP protocol. This is where the Application Service pattern from DDD becomes essential.\n",
    "\n",
    "The application service sits between the domain layer and the external world (in this case, MCP clients). It has a specific responsibility: **orchestrate domain objects to fulfill complete use cases** while handling protocol-specific concerns.\n",
    "\n",
    "Our `WeatherMCPService` serves as the translator between MCP protocol requirements and our weather domain capabilities:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cab977de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from typing import Callable, List, Tuple\n",
      "\n",
      "from mcp.server.fastmcp import FastMCP\n",
      "\n",
      "from servers.weather_service.domain.repository.interfaces import (\n",
      "    WeatherAlertRepository,\n",
      "    WeatherForecastRepository,\n",
      ")\n",
      "from servers.weather_service.domain.service.interfaces import WeatherService\n",
      "from servers.weather_service.infrastructure.application import MCPApplicationService\n",
      "\n",
      "\n",
      "class WeatherMCPService(MCPApplicationService):\n",
      "    \"\"\"MCP Application Service for weather domain operations.\n",
      "\n",
      "    Exposes weather domain capabilities through the Model Context Protocol.\n",
      "    Orchestrates WeatherService and Repository operations while maintaining\n",
      "    separation from MCP protocol details.\n",
      "\n",
      "    Available Tools:\n",
      "        - get_forecast: Real-time weather forecast retrieval\n",
      "        - get_alerts: Current weather alerts for US states\n",
      "\n",
      "    Available Resources:\n",
      "        - historical://alerts/{state}: Historical alert data\n",
      "\n",
      "    Available Prompts:\n",
      "        - weather_analysis_prompt: Structured weather analysis template\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(\n",
      "        self,\n",
      "        mcp: FastMCP,\n",
      "        weather_service: WeatherService,\n",
      "        weather_forecast_repository: WeatherForecastRepository,\n",
      "        weather_alert_repository: WeatherAlertRepository,\n",
      "    ):\n",
      "        self.weather_service = weather_service\n",
      "        self.weather_forecast_repository = weather_forecast_repository\n",
      "        self.weather_alert_repository = weather_alert_repository\n",
      "        super().__init__(mcp)\n",
      "\n",
      "    @property\n",
      "    def tools(self) -> List[Tuple[str, str, Callable]]:\n",
      "        \"\"\"Register tools for the MCP server\"\"\"\n",
      "        return [\n",
      "            (\n",
      "                \"get_forecast\",\n",
      "                \"Get weather forecast for a location\",\n",
      "                self.get_forecast,\n",
      "            ),\n",
      "            (\n",
      "                \"get_alerts\",\n",
      "                \"Get weather alerts for a US state\",\n",
      "                self.get_alerts,\n",
      "            ),\n",
      "        ]\n",
      "\n",
      "    @property\n",
      "    def resources(self) -> List[Tuple[str, str, str, Callable]]:\n",
      "        \"\"\"Register resources for the MCP server\"\"\"\n",
      "        return [\n",
      "            (\n",
      "                \"historical://alerts/{state}\",\n",
      "                \"Get historical weather alerts for a US state\",\n",
      "                \"Get historical weather alerts for a US state. State should be provided as a two-letter US state code (e.g. CA, NY). Do not use this for current alerts.\",\n",
      "                self.get_historical_alerts,\n",
      "            ),\n",
      "        ]\n",
      "\n",
      "    @property\n",
      "    def prompts(self) -> List[Tuple[str, str, Callable]]:\n",
      "        \"\"\"Register prompts for the MCP server\"\"\"\n",
      "        return [\n",
      "            (\n",
      "                \"weather_analysis\",\n",
      "                \"Analyze weather conditions for a location\",\n",
      "                self.weather_analysis_prompt,\n",
      "            ),\n",
      "        ]\n",
      "\n",
      "    def weather_analysis_prompt(self, location: str) -> str:\n",
      "        \"\"\"\n",
      "        A prompt template for analyzing weather conditions for a location.\n",
      "\n",
      "        Args:\n",
      "            location: The location to analyze weather for\n",
      "        \"\"\"\n",
      "        return f\"\"\"\n",
      "        You are a weather analysis expert providing detailed insights about weather conditions.\n",
      "        \n",
      "        Analyze the current and forecasted weather conditions for {location}. \n",
      "        Include information about:\n",
      "        - Current temperatures and conditions\n",
      "        - Expected changes over the next few days\n",
      "        - Any notable weather patterns or anomalies\n",
      "        - Practical advice based on the conditions\n",
      "        \n",
      "        Present your analysis in a clear, structured format that's easy to understand.\n",
      "        \"\"\"\n",
      "\n",
      "    async def get_forecast(self, latitude: float, longitude: float) -> str:\n",
      "        \"\"\"MCP tool: Get weather forecast for coordinates.\n",
      "\n",
      "        Retrieves current forecast from weather service and persists\n",
      "        to repository for historical tracking. Coordinates are validated\n",
      "        and forecast is formatted for LLM consumption.\n",
      "\n",
      "        Args:\n",
      "            latitude: Decimal degrees latitude [-90, 90]\n",
      "            longitude: Decimal degrees longitude [-180, 180]\n",
      "\n",
      "        Returns:\n",
      "            Human-readable forecast string with periods and metadata\n",
      "\n",
      "        Note:\n",
      "            This is an MCP tool function - return values should be\n",
      "            formatted for LLM understanding rather than programmatic use.\n",
      "        \"\"\"\n",
      "        forecast = await self.weather_service.get_forecast(latitude, longitude)\n",
      "        await self.weather_forecast_repository.save_forecast(\n",
      "            latitude, longitude, forecast\n",
      "        )\n",
      "        return forecast.to_display_string()\n",
      "\n",
      "    async def get_alerts(self, state: str) -> str:\n",
      "        \"\"\"Retrieve active weather alerts for a US state.\n",
      "\n",
      "        Fetches current weather warnings, watches, and advisories from the\n",
      "        National Weather Service for the specified state. Returns all active\n",
      "        alerts regardless of severity level.\n",
      "\n",
      "        Args:\n",
      "            state: Two-letter US state code (e.g., \"CA\", \"TX\", \"FL\")\n",
      "                   Case-insensitive, automatically normalized to uppercase\n",
      "\n",
      "        Returns:\n",
      "            List of active WeatherAlert objects, empty list if no alerts\n",
      "\n",
      "        \"\"\"\n",
      "        alerts = await self.weather_service.get_alerts(state)\n",
      "\n",
      "        if not alerts:\n",
      "            return f\"No active alerts for {state}\"\n",
      "\n",
      "        await self.weather_alert_repository.save_alerts(state, alerts)\n",
      "\n",
      "        return \"\\n---\\n\".join(alert.to_display_string() for alert in alerts)\n",
      "\n",
      "    async def get_historical_alerts(self, state: str) -> str:\n",
      "        \"\"\"MCP resource handler for historical weather alerts.\n",
      "\n",
      "        Provides access to recently cached weather alerts through the MCP\n",
      "        resource system. This allows LLMs to access historical alert data\n",
      "        for analysis and comparison.\n",
      "\n",
      "        URI Template: historical://alerts/{state}\n",
      "\n",
      "        Args:\n",
      "            state: Two-letter US state code (e.g., \"CA\", \"TX\")\n",
      "\n",
      "        Returns:\n",
      "            Formatted historical alerts or \"no data\" message\n",
      "\n",
      "        Note:\n",
      "            This is a resource handler, not a tool. Resources provide\n",
      "            read-only access to data, while tools perform actions.\n",
      "        \"\"\"\n",
      "        alerts = await self.weather_alert_repository.get_alerts(\n",
      "            state=state,\n",
      "        )\n",
      "\n",
      "        if not alerts:\n",
      "            return f\"No historical alerts found for {state}\"\n",
      "\n",
      "        return \"\\n\\n===\\n\\n\".join(alert_set.to_display_string() for alert_set in alerts)\n"
     ]
    }
   ],
   "source": [
    "!cat ../src/servers/weather_service/application/mcp_server.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaf6f3f",
   "metadata": {},
   "source": [
    "Notice how this application service:\n",
    "- **Orchestrates** domain services and repositories without containing business logic\n",
    "- **Translates** between domain models and MCP protocol requirements  \n",
    "- **Coordinates** multiple operations (fetch data, persist it, format response)\n",
    "- **Exposes both tools and resources** through MCP\n",
    "\n",
    "Additionally, our the application service takes its dependencies through constructor injection. This allows us to compose different implementations—a production service with real APIs and databases, or a test service with mocks and stubs.\n",
    "\n",
    "Once again, we have abstracted much of the technical complexity to `MCPApplicationService` our infrastructure layer, so the implementation of our application service is focused on our domain.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6fcf38b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from abc import ABC, abstractmethod\n",
      "from typing import Callable, List, Tuple\n",
      "\n",
      "from mcp.server.fastmcp import FastMCP\n",
      "\n",
      "\n",
      "class MCPApplicationService(ABC):\n",
      "    \"\"\"Base class for MCP Application Services following DDD patterns.\n",
      "\n",
      "    Application Services orchestrate domain objects to fulfill use cases\n",
      "    while remaining independent of infrastructure concerns. This class\n",
      "    provides the MCP-specific infrastructure setup.\n",
      "\n",
      "    In DDD terms:\n",
      "    - Tools map to domain service operations\n",
      "    - Resources provide read-only access to aggregates\n",
      "    - Prompts offer templated workflows\n",
      "\n",
      "    Args:\n",
      "        mcp: FastMCP server instance for protocol handling\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, mcp: FastMCP):\n",
      "        self.mcp = mcp\n",
      "\n",
      "        self._register_tools()\n",
      "        self._register_resources()\n",
      "        self._register_prompts()\n",
      "\n",
      "    @property\n",
      "    @abstractmethod\n",
      "    def tools(self) -> List[Tuple[str, str, Callable]]:\n",
      "        pass\n",
      "\n",
      "    @property\n",
      "    @abstractmethod\n",
      "    def resources(self) -> List[Tuple[str, str, str, Callable]]:\n",
      "        pass\n",
      "\n",
      "    @property\n",
      "    @abstractmethod\n",
      "    def prompts(self) -> List[Tuple[str, str, Callable]]:\n",
      "        pass\n",
      "\n",
      "    def _register_tools(self):\n",
      "        \"\"\"Register MCP tools\"\"\"\n",
      "        for name, description, tool in self.tools:\n",
      "            self.mcp.tool(name=name, description=description)(tool)\n",
      "\n",
      "    def _register_resources(self):\n",
      "        \"\"\"Register MCP resources\"\"\"\n",
      "        for uri, name, description, resource in self.resources:\n",
      "            self.mcp.resource(uri, name=name, description=description)(resource)\n",
      "\n",
      "    def _register_prompts(self):\n",
      "        \"\"\"Register MCP prompts\"\"\"\n",
      "        for name, description, prompt in self.prompts:\n",
      "            self.mcp.prompt(name=name, description=description)(prompt)\n",
      "\n",
      "    def run(self, transport: str = \"stdio\"):\n",
      "        \"\"\"Run the MCP server\"\"\"\n",
      "        self.mcp.run(transport=transport)\n"
     ]
    }
   ],
   "source": [
    "!cat ../src/servers/weather_service/infrastructure/application.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ad975f",
   "metadata": {},
   "source": [
    "### Understanding Our MCP Server's Capabilities\n",
    "\n",
    "Our domain-driven weather server demonstrates all three MCP capability types:\n",
    "\n",
    "**Tools (Active Operations)**:\n",
    "- `get_forecast(latitude, longitude)`: Fetches real-time weather data and persists it for historical tracking\n",
    "- `get_alerts(state)`: Retrieves current weather alerts and saves them as snapshots\n",
    "\n",
    "**Resources (Contextual Data)**:\n",
    "- `historical://alerts/{state}`: Provides read-only access to previously cached alert data\n",
    "- Resource templates like this enable LLMs to construct parameterized requests (`historical://alerts/CA`)\n",
    "\n",
    "**Prompts (Workflow Templates)**:\n",
    "- `weather_analysis_prompt(location)`: Structures comprehensive weather analysis requests\n",
    "- Prompts guide LLMs toward specific reasoning patterns and output formats\n",
    "\n",
    "This combination allows for sophisticated interactions: an LLM can use tools for current data, resources for historical context, and prompts for structured analysis—all coordinated through the client."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09a3808",
   "metadata": {},
   "source": [
    "## Building MCP Clients\n",
    "\n",
    "While our domain-driven server provides clean, well-structured capabilities, the client is equally important—it determines how LLMs discover, select, and coordinate these capabilities to fulfill user requests. The client acts as the intelligent orchestrator, bridging human intent with server capabilities.\n",
    "\n",
    "In the MCP ecosystem, clients act as the bridge between users and MCP servers. While servers expose capabilities (tools, resources, prompts), clients orchestrate how these capabilities are used:\n",
    "\n",
    "- **Discovery**: Clients connect to servers and discover available tools, resources, and prompts\n",
    "- **Selection**: Clients decide which capabilities to use based on user queries\n",
    "- **Coordination**: Clients manage the conversation flow, calling tools and loading resources\n",
    "- **Context Management**: Clients control what information gets provided to the LLM\n",
    "\n",
    "This separation allows the same MCP server to work with different client strategies—from simple tool calling to sophisticated workflow orchestration.\n",
    "\n",
    "The Model Context Protocol gives us flexibility in client design. We can build simple clients that just call tools, or sophisticated clients that intelligently manage resources and apply workflow templates. Let's explore three different approaches, each suited to different interaction patterns.\n",
    "\n",
    "Let's explore three different client strategies that showcase MCP's flexibility:\n",
    "\n",
    "### 1. Simple Chat Client: Basic Tool Coordination\n",
    "\n",
    "This client demonstrates the fundamental MCP interaction pattern: the LLM discovers available tools, decides when to use them based on user queries, and incorporates their results into the conversation flow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1804a93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import logging\n",
      "from contextlib import AsyncExitStack\n",
      "from typing import Optional\n",
      "\n",
      "from mcp import ClientSession, StdioServerParameters\n",
      "from mcp.client.stdio import stdio_client\n",
      "\n",
      "from client.providers.base import LLMProvider\n",
      "\n",
      "logger = logging.getLogger(__name__)\n",
      "\n",
      "\n",
      "class SimpleChatMCPClient:\n",
      "    \"\"\"Basic MCP client with tool calling and conversation management.\n",
      "\n",
      "    Provides core MCP functionality:\n",
      "    - Connects to MCP servers via stdio\n",
      "    - Discovers and calls tools\n",
      "    - Manages conversation state with LLM providers\n",
      "    - Handles interactive chat sessions\n",
      "\n",
      "    Args:\n",
      "        llm_provider: LLM service provider (Azure OpenAI, Anthropic, etc.)\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, llm_provider: LLMProvider):\n",
      "        # Initialize session and client objects\n",
      "        self.session: Optional[ClientSession] = None\n",
      "        self.exit_stack = AsyncExitStack()\n",
      "        self.provider = llm_provider\n",
      "        self.available_resources = []\n",
      "        self.resource_templates = []\n",
      "        self.available_prompts = []\n",
      "\n",
      "    async def connect_to_server(self, server_script_path: str):\n",
      "        \"\"\"Connect to an MCP server\"\"\"\n",
      "        is_python = server_script_path.endswith(\".py\")\n",
      "        is_js = server_script_path.endswith(\".js\")\n",
      "        if not (is_python or is_js):\n",
      "            raise ValueError(\"Server script must be a .py or .js file\")\n",
      "\n",
      "        command = \"python\" if is_python else \"node\"\n",
      "        server_params = StdioServerParameters(\n",
      "            command=command, args=[server_script_path], env=None\n",
      "        )\n",
      "\n",
      "        stdio_transport = await self.exit_stack.enter_async_context(\n",
      "            stdio_client(server_params)\n",
      "        )\n",
      "        self.stdio, self.write = stdio_transport\n",
      "        self.session = await self.exit_stack.enter_async_context(\n",
      "            ClientSession(self.stdio, self.write)\n",
      "        )\n",
      "\n",
      "        await self.session.initialize()\n",
      "        await self.provider.initialize()\n",
      "\n",
      "        await self.discover_tools()\n",
      "        await self._discover_resources()\n",
      "        await self._discover_prompts()\n",
      "\n",
      "    async def discover_tools(self):\n",
      "        response = await self.session.list_tools()\n",
      "        self._mcp_server_tools = response.tools\n",
      "        self._formatted_tools = await self.provider.format_tools_for_model(\n",
      "            self._mcp_server_tools\n",
      "        )\n",
      "        logger.info(\n",
      "            f\"Connected to server with tools: {[tool.name for tool in self._mcp_server_tools]}\"\n",
      "        )\n",
      "\n",
      "    async def _discover_resources(self):\n",
      "        \"\"\"Discover available resources and resource templates from MCP server.\n",
      "\n",
      "        MCP servers can expose two types of resources:\n",
      "        1. Concrete resources: Fixed URIs with static content\n",
      "        2. Resource templates: URI patterns with parameters (e.g., \"user://{id}\")\n",
      "\n",
      "        This method queries both endpoints and stores the results for later\n",
      "        resource selection and loading.\n",
      "\n",
      "        Populates:\n",
      "            self.available_resources: List of concrete resource descriptors\n",
      "            self.resource_templates: List of parameterized resource templates\n",
      "        \"\"\"\n",
      "        if not self.session:\n",
      "            logger.error(\"Cannot discover resources: No active session\")\n",
      "            return\n",
      "\n",
      "        try:\n",
      "            # First, get concrete resources\n",
      "            logger.info(\"Discovering concrete resources...\")\n",
      "            resources_response = await self.session.list_resources()\n",
      "\n",
      "            # Then, get resource templates\n",
      "            logger.info(\"Discovering resource templates...\")\n",
      "            templates_response = await self.session.list_resource_templates()\n",
      "\n",
      "            # Store both concrete resources and resource templates\n",
      "            self.available_resources = []\n",
      "            self.resource_templates = []\n",
      "\n",
      "            # Process concrete resources\n",
      "            if hasattr(resources_response, \"resources\"):\n",
      "                for resource in resources_response.resources:\n",
      "                    if hasattr(resource, \"uri\"):\n",
      "                        self.available_resources.append(\n",
      "                            {\n",
      "                                \"uri\": resource.uri,\n",
      "                                \"name\": resource.name,\n",
      "                                \"description\": getattr(resource, \"description\", \"\"),\n",
      "                                \"mimeType\": getattr(resource, \"mimeType\", \"text/plain\"),\n",
      "                            }\n",
      "                        )\n",
      "\n",
      "            # Process resource templates\n",
      "            if hasattr(templates_response, \"resourceTemplates\"):\n",
      "                for template in templates_response.resourceTemplates:\n",
      "                    if hasattr(template, \"uriTemplate\"):\n",
      "                        self.resource_templates.append(\n",
      "                            {\n",
      "                                \"uriTemplate\": template.uriTemplate,\n",
      "                                \"name\": template.name,\n",
      "                                \"description\": getattr(template, \"description\", \"\"),\n",
      "                                \"mimeType\": getattr(template, \"mimeType\", \"text/plain\"),\n",
      "                            }\n",
      "                        )\n",
      "\n",
      "            # Log discovered resources\n",
      "            logger.info(\n",
      "                f\"Discovered {len(self.available_resources)} concrete resources\"\n",
      "            )\n",
      "            logger.info(f\"Discovered {len(self.resource_templates)} resource templates\")\n",
      "\n",
      "            for template in self.resource_templates:\n",
      "                logger.info(f\"Template: {template['uriTemplate']}\")\n",
      "\n",
      "        except Exception as e:\n",
      "            logger.error(f\"Error discovering resources: {str(e)}\")\n",
      "\n",
      "    async def _discover_prompts(self):\n",
      "        \"\"\"Discover prompt templates available from the MCP server.\n",
      "\n",
      "        Prompts in MCP are user-controlled templates that provide standardized\n",
      "        ways to initiate specific types of conversations. They can accept\n",
      "        parameters and return structured prompt content.\n",
      "\n",
      "        Populates:\n",
      "            self.available_prompts: List of prompt descriptors with metadata\n",
      "        \"\"\"\n",
      "        if not self.session:\n",
      "            return\n",
      "\n",
      "        try:\n",
      "            prompts_response = await self.session.list_prompts()\n",
      "            self.available_prompts = []\n",
      "\n",
      "            if hasattr(prompts_response, \"prompts\"):\n",
      "                for prompt in prompts_response.prompts:\n",
      "                    self.available_prompts.append(\n",
      "                        {\n",
      "                            \"name\": prompt.name,\n",
      "                            \"description\": getattr(prompt, \"description\", \"\"),\n",
      "                            \"arguments\": getattr(prompt, \"arguments\", []),\n",
      "                        }\n",
      "                    )\n",
      "\n",
      "            logger.info(f\"Discovered {len(self.available_prompts)} prompts\")\n",
      "        except Exception as e:\n",
      "            logger.error(f\"Error discovering prompts: {str(e)}\")\n",
      "\n",
      "    async def handle_user_query(self, query: str) -> str:\n",
      "        \"\"\"Process a query using the LLM provider and available tools\"\"\"\n",
      "\n",
      "        # Add the user's query\n",
      "        await self.provider.add_user_message(query)\n",
      "\n",
      "        response_parts = []\n",
      "\n",
      "        while True:\n",
      "            # Get next response from provider (text and any tool calls)\n",
      "            text, tool_calls = await self.provider.get_model_response(\n",
      "                self._formatted_tools\n",
      "            )\n",
      "\n",
      "            if text:\n",
      "                response_parts.append(text)\n",
      "\n",
      "            # If no tool calls, we're done\n",
      "            if not tool_calls:\n",
      "                break\n",
      "\n",
      "            # Process each tool call\n",
      "            for tool_call in tool_calls:\n",
      "                tool_name = tool_call[\"name\"]\n",
      "                tool_args = tool_call[\"arguments\"]\n",
      "                tool_call_id = tool_call.get(\"id\")\n",
      "\n",
      "                logger.info(f\"[Calling tool {tool_name} with args {tool_args}]\")\n",
      "\n",
      "                # Execute tool call via MCP\n",
      "                result = await self.session.call_tool(tool_name, tool_args)\n",
      "\n",
      "                # Add tool result to conversation\n",
      "                await self.provider.process_tool_result(\n",
      "                    tool_name,\n",
      "                    result,\n",
      "                    tool_call_id,\n",
      "                )\n",
      "\n",
      "        return \"\\n\".join([text for text in response_parts if text])\n",
      "\n",
      "    async def start_interactive_session(self):\n",
      "        \"\"\"Run an interactive chat loop\"\"\"\n",
      "        print(\"\\nMCP Client Started!\")\n",
      "        print(\"Type your queries or 'quit' to exit.\")\n",
      "\n",
      "        while True:\n",
      "            try:\n",
      "                query = input(\"\\nQuery: \").strip()\n",
      "\n",
      "                if query.lower() == \"quit\":\n",
      "                    await self.cleanup()\n",
      "                    break\n",
      "\n",
      "                response = await self.handle_user_query(query)\n",
      "                print(\"\\n\" + response)\n",
      "\n",
      "            except Exception as e:\n",
      "                print(f\"\\nError: {str(e)}\")\n",
      "\n",
      "    async def cleanup(self):\n",
      "        \"\"\"Clean up resources\"\"\"\n",
      "        await self.exit_stack.aclose()\n"
     ]
    }
   ],
   "source": [
    "!cat ../src/client/simple_client.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1c564f",
   "metadata": {},
   "source": [
    "Now, let's use our client to interact with our server.\n",
    "\n",
    "```console\n",
    "python src/chat.py src/run_weather_service.py azure simple\n",
    "\n",
    "MCP Client Started!\n",
    "Type your queries or 'quit' to exit.\n",
    "\n",
    "Query: What is the forecast for Austin Texas?\n",
    "INFO:httpx:HTTP Request: POST https://dev-ch-uk.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
    "INFO:client.simple_client:[Calling tool get_forecast with args {'latitude': 30.2672, 'longitude': -97.7431}]\n",
    "INFO:mcp.server.lowlevel.server:Processing request of type CallToolRequest\n",
    "INFO:httpx:HTTP Request: GET https://api.weather.gov/points/30.2672,-97.7431 \"HTTP/1.1 200 OK\"\n",
    "INFO:httpx:HTTP Request: GET https://api.weather.gov/gridpoints/EWX/156,91/forecast \"HTTP/1.1 200 OK\"\n",
    "INFO:httpx:HTTP Request: POST https://dev-ch-uk.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
    "\n",
    "Here is the forecast for Austin, Texas:\n",
    "\n",
    "- Overnight: Mostly cloudy, low around 76°F. South wind around 5 mph.\n",
    "- Saturday: Mostly sunny, high near 99°F. Heat index up to 105°F. South wind 5–10 mph, gusts up to 25 mph.\n",
    "- Saturday Night: Mostly cloudy, low around 76°F. Heat index up to 102°F. South wind 5–10 mph, gusts up to 25 mph.\n",
    "- Sunday: Partly sunny, high near 98°F. Heat index up to 105°F. South wind 5–10 mph, gusts up to 25 mph.\n",
    "- Sunday Night: Slight chance of showers and thunderstorms after 7pm. Mostly cloudy, low around 76°F. South southeast wind 10–15 mph, gusts up to 25 mph. Chance of precipitation is 20%.\n",
    "\n",
    "Stay cool and hydrated—it's going to be hot!\n",
    "\n",
    "Query: Are there any alerts in Texas at the moment?\n",
    "INFO:httpx:HTTP Request: POST https://dev-ch-uk.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
    "INFO:client.simple_client:[Calling tool get_alerts with args {'state': 'TX'}]\n",
    "INFO:mcp.server.lowlevel.server:Processing request of type CallToolRequest\n",
    "INFO:httpx:HTTP Request: GET https://api.weather.gov/alerts/active/area/TX \"HTTP/1.1 200 OK\"\n",
    "INFO:httpx:HTTP Request: POST https://dev-ch-uk.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
    "\n",
    "Yes, there are several weather alerts in Texas at the moment:\n",
    "\n",
    "1. Heat Advisory:\n",
    "   - Areas: Jim Wells, Inland Kleberg, Inland Nueces, Inland San Patricio Counties\n",
    "   - Heat index values up to 111°F expected from 1 PM to 7 PM CDT today.\n",
    "   - Impacts: Hot temperatures and high humidity may cause heat illnesses.\n",
    "   - Advice: Drink plenty of fluids, stay in air conditioning, avoid the sun, and check on relatives and neighbors.\n",
    "\n",
    "2. Flood Warning (Neches River near Diboll):\n",
    "   - Areas: Angelina, Houston, Polk, Trinity, Tyler Counties\n",
    "   - Minor flooding is occurring and forecast to continue until Sunday evening.\n",
    "   - Impacts: Flooded boat ramps and trails; minor lowland flooding.\n",
    "   - Advice: Do not drive through flooded areas. Turn around, don’t drown.\n",
    "\n",
    "3. Flood Warning (Sabine River near Deweyville):\n",
    "   - Areas: Newton, Orange Counties (TX) and Beauregard, Calcasieu (LA)\n",
    "   - Minor flooding is occurring and forecast to continue.\n",
    "   - Impacts: Minor lowland flooding at 24.0 feet river stage.\n",
    "   - Advice: Stay updated and avoid flooded areas.\n",
    "\n",
    "If you need more details for a specific area, let me know!\n",
    "\n",
    "```\n",
    "\n",
    "That looks like it worked well; successfully using our tools where appropriate!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3dbd48",
   "metadata": {},
   "source": [
    "### 2. LLM Resource Selector: AI-Driven Context Management\n",
    "\n",
    "Now, let's extend our client so that it can access the resource that we defined on our server; using an LLM to select which resources to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35e77555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import logging\n",
      "\n",
      "from client.providers.base import LLMProvider\n",
      "from client.simple_client import SimpleChatMCPClient\n",
      "\n",
      "logger = logging.getLogger(__name__)\n",
      "\n",
      "\n",
      "class LLMResourceSelector(SimpleChatMCPClient):\n",
      "    \"\"\"MCP client that uses LLM intelligence to select relevant resources.\n",
      "\n",
      "    Extends basic client with smart resource selection. Before processing\n",
      "    queries, asks the LLM to analyze available resources and load only\n",
      "    those relevant to the user's request.\n",
      "\n",
      "    This reduces token usage and improves response quality by providing\n",
      "    focused context rather than all available resources.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, llm_provider: LLMProvider):\n",
      "        super().__init__(llm_provider)\n",
      "        self.resource_templates = []\n",
      "        self.available_resources = []\n",
      "\n",
      "    async def handle_user_query(self, query: str) -> str:\n",
      "        \"\"\"\n",
      "        Process a query using LLM-driven resource selection\n",
      "        \"\"\"\n",
      "        # First, have the LLM analyze the query to determine which resources to use\n",
      "        resource_uris = await self._select_relevant_resources(query)\n",
      "\n",
      "        if resource_uris:\n",
      "            logger.info(f\"Identified resources as relevant: {resource_uris}\")\n",
      "            # Load the selected resources\n",
      "            resource_content = await self._load_resources(resource_uris)\n",
      "\n",
      "            # Enhance the query with the selected resources\n",
      "            enhanced_query = (\n",
      "                f\"I have the following information that may be relevant to the query:\\n\\n\"\n",
      "                f\"{resource_content}\\n\\n\"\n",
      "                f\"Using this information where relevant, please answer: {query}\"\n",
      "                \"You do not have to use a resource if you don't think it will help, you may also use any tools you have\\n\\n\"\n",
      "            )\n",
      "\n",
      "            # Use the enhanced query\n",
      "            return await super().handle_user_query(enhanced_query)\n",
      "        else:\n",
      "            # No relevant resources identified, use the original query\n",
      "            return await super().handle_user_query(query)\n",
      "\n",
      "    async def _select_relevant_resources(self, query: str) -> list:\n",
      "        \"\"\"\n",
      "        Have the LLM decide which resources would be relevant for the given query.\n",
      "        Returns a list of resource URIs to load.\n",
      "        \"\"\"\n",
      "        # Create a summary of available resources for the LLM\n",
      "        resource_descriptions = self._format_resource_descriptions()\n",
      "\n",
      "        # Create a prompt for resource selection\n",
      "        resource_selection_prompt = (\n",
      "            f\"I need to determine which resources would help answer this query: '{query}'\\n\\n\"\n",
      "            f\"Available resources:\\n{resource_descriptions}\\n\\n\"\n",
      "            f\"For resource templates, I need to determine appropriate parameter values.\\n\\n\"\n",
      "            f\"Analyze the query and list only the URIs of resources that would be helpful, \"\n",
      "            f\"with any parameter substitutions for templates. Format as a JSON list.\"\n",
      "        )\n",
      "\n",
      "        # Ask the LLM to select resources\n",
      "        await self.provider.add_user_message(resource_selection_prompt)\n",
      "        response_text, _ = await self.provider.get_model_response([])\n",
      "\n",
      "        # Extract the resource URIs from the response\n",
      "        return self._extract_resource_uris(response_text)\n",
      "\n",
      "    def _format_resource_descriptions(self) -> str:\n",
      "        \"\"\"Format resource descriptions for the LLM prompt\"\"\"\n",
      "        descriptions = []\n",
      "\n",
      "        for resource in self.available_resources:\n",
      "            descriptions.append(\n",
      "                f\"- {resource['name']}: {resource['uri']} - {resource['description']}\"\n",
      "            )\n",
      "\n",
      "        for template in self.resource_templates:\n",
      "            descriptions.append(\n",
      "                f\"- {template['name']}: {template['uriTemplate']} - {template['description']}\"\n",
      "            )\n",
      "\n",
      "        return \"\\n\".join(descriptions)\n",
      "\n",
      "    def _extract_resource_uris(self, response_text: str) -> list:\n",
      "        \"\"\"Extract resource URIs from LLM response\"\"\"\n",
      "        import json\n",
      "        import re\n",
      "\n",
      "        # Try to find and parse a JSON list in the response\n",
      "        json_match = re.search(r\"\\[.*?\\]\", response_text, re.DOTALL)\n",
      "        if json_match:\n",
      "            try:\n",
      "                return json.loads(json_match.group(0))\n",
      "            except json.JSONDecodeError:\n",
      "                pass\n",
      "\n",
      "        # Fallback: extract anything that looks like a resource URI\n",
      "        uri_pattern = r'(([a-zA-Z0-9_-]+)://[^\\s,\"\\']*)'\n",
      "        matches = re.findall(uri_pattern, response_text)\n",
      "        if matches:\n",
      "            return [match[0] for match in matches]\n",
      "\n",
      "        return []\n",
      "\n",
      "    async def _load_resources(self, resource_uris: list) -> str:\n",
      "        \"\"\"Load the content of selected resources\"\"\"\n",
      "        resource_sections = []\n",
      "\n",
      "        for uri in resource_uris:\n",
      "            resource_sections.append(f\"\\n\\nRESOURCE: {uri}\\n\")\n",
      "            try:\n",
      "                # Fetch the resource content\n",
      "                response = await self.session.read_resource(uri)\n",
      "                for response_contents in response.contents:\n",
      "                    # Add to the collection with metadata\n",
      "                    resource_sections.append(f\"\\n{response_contents}\")\n",
      "            except Exception as e:\n",
      "                logger.error(f\"Error loading resource {uri}: {str(e)}\")\n",
      "\n",
      "        return \"\\n\\n\".join(resource_sections)\n"
     ]
    }
   ],
   "source": [
    "!cat ../src/client/resource_selector_client.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d846b5e3",
   "metadata": {},
   "source": [
    " For a weather query about California patterns, it might automatically load `historical://alerts/CA` to provide historical context alongside current weather tools, let's try it out.\n",
    "\n",
    " ```console\n",
    " python src/chat.py src/run_weather_service.py azure resource_selector\n",
    "\n",
    "INFO:client.simple_client:Discovered 1 resource templates\n",
    "INFO:client.simple_client:Template: historical://alerts/{state}\n",
    "\n",
    "MCP Client Started!\n",
    "Type your queries or 'quit' to exit.\n",
    "\n",
    "Query: Are there any active weather alerts in California?\n",
    "INFO:httpx:HTTP Request: POST https://dev-ch-uk.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
    "INFO:httpx:HTTP Request: POST https://dev-ch-uk.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
    "INFO:client.simple_client:[Calling tool get_alerts with args {'state': 'CA'}]\n",
    "INFO:mcp.server.lowlevel.server:Processing request of type CallToolRequest\n",
    "INFO:httpx:HTTP Request: GET https://api.weather.gov/alerts/active/area/CA \"HTTP/1.1 200 OK\"\n",
    "INFO:httpx:HTTP Request: POST https://dev-ch-uk.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
    "\n",
    "Yes, there are several active weather alerts in California:\n",
    "\n",
    "- Wind Advisories for San Gorgonio Pass near Banning and Santa Barbara County Southwestern Coast/Santa Ynez Mountains Western Range, with strong winds expected.\n",
    "- Beach Hazards Statements for Ventura County, Malibu Coast, Los Angeles County, San Diego County, and Orange County beaches, warning of high surf and dangerous rip currents.\n",
    "\n",
    "If you need details about a specific area or alert, let me know!\n",
    "\n",
    "Query: Do you have access to historical weather alerts in the same area?\n",
    "INFO:httpx:HTTP Request: POST https://dev-ch-uk.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
    "INFO:client.resource_selector_client:Identified resources as relevant: ['historical://alerts/CA']\n",
    "INFO:mcp.server.lowlevel.server:Processing request of type ReadResourceRequest\n",
    "INFO:httpx:HTTP Request: POST https://dev-ch-uk.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
    "\n",
    "Yes, I have access to historical weather alerts for California. For example, I can provide details about past alerts such as wind advisories, beach hazards statements, and air quality alerts for areas like San Gorgonio Pass, Ventura County Beaches, Malibu Coast, Los Angeles County Beaches, San Diego County Coastal Areas, Orange County, Santa Barbara County, and Coachella Valley. If you need information about specific historical alerts or time periods, let me know!\n",
    "\n",
    "Query: Can you give me an example of a historical weather alert in California, with the date it was active?\n",
    "INFO:httpx:HTTP Request: POST https://dev-ch-uk.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
    "INFO:client.resource_selector_client:Identified resources as relevant: ['historical://alerts/CA']\n",
    "INFO:mcp.server.lowlevel.server:Processing request of type ReadResourceRequest\n",
    "INFO:httpx:HTTP Request: POST https://dev-ch-uk.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
    "\n",
    "Yes, here is an example of a historical weather alert in California, including the date it was active:\n",
    "\n",
    "Event: Wind Advisory  \n",
    "Area: San Gorgonio Pass Near Banning  \n",
    "Severity: Moderate  \n",
    "Description: West winds 25 to 35 mph with gusts up to 55 mph expected.  \n",
    "When: Until 3 AM PDT Sunday (active as of May 24, 2025)  \n",
    "Impacts: Gusty winds will blow around unsecured objects. Reduced visibility in blowing dust.  \n",
    "Instructions: Winds this strong can make driving difficult, especially for high profile vehicles. Use extra caution.\n",
    "\n",
    "This alert was active around May 24, 2025.\n",
    "\n",
    " ```\n",
    "\n",
    "\n",
    "\n",
    "**Important Note**: In MCP, it's the **client's responsibility** to provide resources to the LLM context. Here we've chosen to use an LLM to analyze queries and select appropriate resources, but this is just one approach. You could equally implement resource selection using:\n",
    "\n",
    "- **Regex patterns**: Match query keywords to resource categories\n",
    "- **Business rules**: \"Always load historical data for trend analysis queries\"\n",
    "- **Configuration-driven selection**: User-defined mappings between query types and resources\n",
    "- **Hybrid approaches**: Combine multiple selection strategies\n",
    "\n",
    "The key insight is that MCP provides the resource infrastructure, but the selection strategy is entirely up to your client implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dff6e37",
   "metadata": {},
   "source": [
    "### 3. Prompt-Aware Client: Template-Driven Workflows\n",
    "\n",
    "This client demonstrates MCP's prompt system, automatically recognizing when users want to invoke structured workflows and applying the appropriate templates to guide the LLM's response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "839176ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import json\n",
      "import logging\n",
      "\n",
      "from client.simple_client import SimpleChatMCPClient\n",
      "\n",
      "logger = logging.getLogger(__name__)\n",
      "\n",
      "\n",
      "class PromptAwareMCPClient(SimpleChatMCPClient):\n",
      "    \"\"\"Extends SimpleChatMCPClient with prompt discovery and usage\"\"\"\n",
      "\n",
      "    async def start_interactive_session(self):\n",
      "        \"\"\"Show available prompts at start of interaction\"\"\"\n",
      "        print(\"\\nMCP Client Started!\")\n",
      "\n",
      "        # Show available prompts\n",
      "        if self.available_prompts:\n",
      "            print(\"\\nAvailable MCP Prompts:\")\n",
      "            for i, prompt in enumerate(self.available_prompts, 1):\n",
      "                args = \", \".join([f\"{arg.name}\" for arg in prompt.get(\"arguments\", [])])\n",
      "                print(f\"{i}. {prompt['name']} - {prompt['description']}\")\n",
      "            print(\n",
      "                \"\\nYou can use these prompts in your queries by calling them like Python functions.\"\n",
      "            )\n",
      "\n",
      "        # Use the parent class's interactive session logic\n",
      "        await super().start_interactive_session()\n",
      "\n",
      "    async def handle_user_query(self, query: str) -> str:\n",
      "        \"\"\"\n",
      "        Process a query using LLM-driven resource selection\n",
      "        \"\"\"\n",
      "        # First, have the LLM analyze the query to determine which resources to use\n",
      "        prompt_info = await self._select_relevant_prompt(query)\n",
      "\n",
      "        if prompt_info:\n",
      "            logger.info(f\"Identified prompt call as: {prompt_info}\")\n",
      "            # Load the selected resources\n",
      "\n",
      "            enhanced_query = await self.use_prompt(prompt_info)\n",
      "\n",
      "            # Use the enhanced query\n",
      "            return await super().handle_user_query(enhanced_query)\n",
      "        else:\n",
      "            # No relevant resources identified, use the original query\n",
      "            return await super().handle_user_query(query)\n",
      "\n",
      "    async def _select_relevant_prompt(self, query: str) -> list:\n",
      "        \"\"\"\n",
      "        Have the LLM decide which resources would be relevant for the given query.\n",
      "        Returns a list of resource URIs to load.\n",
      "        \"\"\"\n",
      "\n",
      "        # Create a prompt for prompt selection\n",
      "        prompt_selection_prompt = (\n",
      "            f\"I need to determine whether the user is trying to use an available prompt. \"\n",
      "            f\"Their query is: '{query}'\\n\\n\"\n",
      "            f\"The available prompts you have are:\\n{self.available_prompts}\\n\\n\"\n",
      "            f\"Only use a prompt if the user explicitly asked for it \"\n",
      "            f\"If they are trying to use a prompt, please return the name of the prompt and any arguments \"\n",
      "            f'that should be used as Json with format {{\"prompt_name\": ..., \"arguments\": {{...}}}}. '\n",
      "            f\"If they are not trying to use a prompt, please return an empty Json array.\\n\\n\"\n",
      "        )\n",
      "\n",
      "        # Ask the LLM to select resources\n",
      "        await self.provider.add_user_message(prompt_selection_prompt)\n",
      "        response_text, _ = await self.provider.get_model_response([])\n",
      "\n",
      "        # Extract the prompt name and arguments from the response\n",
      "        try:\n",
      "            response_json = json.loads(response_text)\n",
      "            if isinstance(response_json, dict):\n",
      "                if not response_json:\n",
      "                    return []\n",
      "                prompt_name = response_json.get(\"prompt_name\")\n",
      "                arguments = response_json.get(\"arguments\", {})\n",
      "                if prompt_name and isinstance(arguments, dict):\n",
      "                    return [prompt_name, arguments]\n",
      "        except json.JSONDecodeError:\n",
      "            logger.debug(f\"Failed to parse JSON response: {response_text}\")\n",
      "            return []\n",
      "\n",
      "    async def use_prompt(self, prompt_info) -> str:\n",
      "        \"\"\"Use an MCP prompt with given arguments\"\"\"\n",
      "        try:\n",
      "            prompt_name, arguments = prompt_info\n",
      "            prompt_result = await self.session.get_prompt(prompt_name, arguments)\n",
      "\n",
      "            return prompt_result.messages[0].content.text\n",
      "        except Exception as e:\n",
      "            return f\"Error using prompt '{prompt_info}': {str(e)}\"\n"
     ]
    }
   ],
   "source": [
    "!cat ../src/client/prompt_aware_client.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5151960f",
   "metadata": {},
   "source": [
    "\n",
    "**Flexible Prompt Selection**: As with resource selection, we've chosen to use an LLM to detect when users want to invoke prompt templates, but this is just one approach. Alternative strategies include:\n",
    "\n",
    "- **Keyword matching**: Detect phrases like \"analyze\", \"report on\", or \"summarize\"\n",
    "- **Command prefixes**: Users type a specified format e.g., `/weather-analysis Los Angeles` to explicitly invoke prompts\n",
    "- **Menu-driven selection**: Present available prompts and let users choose\n",
    "- **Context-aware detection**: Analyze conversation history to suggest relevant prompts\n",
    "\n",
    "\n",
    "Let's try it out!\n",
    "\n",
    "\n",
    "```console\n",
    "python src/chat.py src/run_weather_service.py azure prompt_aware\n",
    "INFO:mcp.server.lowlevel.server:Processing request of type ListPromptsRequest\n",
    "INFO:client.simple_client:Discovered 1 prompts\n",
    "\n",
    "MCP Client Started!\n",
    "\n",
    "Available MCP Prompts:\n",
    "1. weather_analysis - Analyze weather conditions for a location\n",
    "\n",
    "You can use these prompts in your queries by calling them like Python functions.\n",
    "\n",
    "MCP Client Started!\n",
    "Type your queries or 'quit' to exit.\n",
    "\n",
    "Query: weather_analysis(Austin, Texas)\n",
    "INFO:httpx:HTTP Request: POST https://dev-ch-uk.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
    "INFO:client.prompt_aware_client:Identified prompt call as: ['weather_analysis', {'location': 'Austin, Texas'}]\n",
    "INFO:mcp.server.lowlevel.server:Processing request of type GetPromptRequest\n",
    "INFO:httpx:HTTP Request: POST https://dev-ch-uk.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
    "INFO:client.simple_client:[Calling tool get_forecast with args {'latitude': 30.2672, 'longitude': -97.7431}]\n",
    "INFO:mcp.server.lowlevel.server:Processing request of type CallToolRequest\n",
    "INFO:httpx:HTTP Request: GET https://api.weather.gov/points/30.2672,-97.7431 \"HTTP/1.1 200 OK\"\n",
    "INFO:httpx:HTTP Request: GET https://api.weather.gov/gridpoints/EWX/156,91/forecast \"HTTP/1.1 200 OK\"\n",
    "INFO:client.simple_client:[Calling tool get_alerts with args {'state': 'TX'}]\n",
    "INFO:mcp.server.lowlevel.server:Processing request of type CallToolRequest\n",
    "INFO:httpx:HTTP Request: GET https://api.weather.gov/alerts/active/area/TX \"HTTP/1.1 200 OK\"\n",
    "INFO:httpx:HTTP Request: POST https://dev-ch-uk.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
    "\n",
    "Weather Analysis for Austin, Texas\n",
    "\n",
    "1. Current Temperatures and Conditions\n",
    "- Overnight: Mostly cloudy, low around 76°F. Light south wind (~5 mph).\n",
    "- Saturday: Mostly sunny, high near 99°F. Heat index values as high as 105°F. South wind 5–10 mph, gusts up to 25 mph.\n",
    "- Saturday Night: Mostly cloudy, low around 76°F. Heat index up to 102°F. South wind 5–10 mph, gusts up to 25 mph.\n",
    "\n",
    "2. Expected Changes Over the Next Few Days\n",
    "- Sunday: Partly sunny, high near 98°F. Heat index values as high as 105°F. South wind 5–10 mph, gusts up to 25 mph.\n",
    "- Sunday Night: Mostly cloudy, low around 77°F. Slight chance (20%) of showers and thunderstorms after 1am. South-southeast wind 5–10 mph, gusts up to 25 mph.\n",
    "\n",
    "3. Notable Weather Patterns or Anomalies\n",
    "- Persistent high temperatures near 100°F with heat index values exceeding 100°F indicate a significant heat wave.\n",
    "- Winds will be moderate, with occasional gusts up to 25 mph.\n",
    "- A slight chance of showers and thunderstorms late Sunday night, but otherwise dry conditions prevail.\n",
    "- No active weather alerts specifically for Austin, but a Heat Advisory is in effect for nearby counties, with heat index values up to 111°F expected elsewhere in Texas.\n",
    "\n",
    "4. Practical Advice Based on Conditions\n",
    "- Heat Safety: The combination of high temperatures and humidity can lead to heat-related illnesses. Limit outdoor activities during peak afternoon hours, stay hydrated, and seek air conditioning when possible.\n",
    "- Monitor Vulnerable Groups: Check on elderly neighbors, children, and pets, as they are more susceptible to heat stress.\n",
    "- Prepare for Gusty Winds: Secure loose outdoor items.\n",
    "- Stay Informed: While no severe weather is forecast for Austin, keep an eye on local updates, especially if traveling to areas under heat advisories or flood warnings.\n",
    "- If you must be outdoors, wear light clothing, use sunscreen, and take frequent breaks in the shade.\n",
    "\n",
    "Summary\n",
    "Austin is experiencing a period of intense heat with little relief at night and only a slight chance of rain late Sunday. Take precautions to avoid heat exhaustion, and stay updated on local weather developments.\n",
    "\n",
    "```\n",
    "\n",
    "Here, we can see that our model used both available tools to provide a comprehensive weather report!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65e0562",
   "metadata": {},
   "source": [
    "## Benefits Realized Through Domain-Driven Design\n",
    "\n",
    "The beauty of this architecture is that each component has a single, clear responsibility:\n",
    "\n",
    "- **Domain models** represent weather concepts using business language\n",
    "- **Domain services** encapsulate weather-specific business rules\n",
    "- **Repositories** manage data persistence with time-based queries\n",
    "- **Application services** orchestrate domain operations for MCP\n",
    "- **Infrastructure** handles external concerns like HTTP and file I/O\n",
    "- **Clients** coordinate between user intent and server capabilities\n",
    "\n",
    "This refactored architecture delivers significant advantages across multiple dimensions:\n",
    "\n",
    "### Testability at Every Layer\n",
    "\n",
    "Each layer can be tested independently with appropriate test doubles:\n",
    "\n",
    "```python\n",
    "# Test domain logic without external dependencies using a STUB\n",
    "async def test_weather_service_handles_api_errors():\n",
    "    # Stub that returns hardcoded responses to simulate API failure\n",
    "    async def http_stub(url, headers=None):\n",
    "        return None  # Hardcoded failure response\n",
    "    \n",
    "    weather_service = NWSWeatherService(http_stub)\n",
    "    forecast = await weather_service.get_forecast(37.7749, -122.4194)\n",
    "    \n",
    "    # Verify business logic handles errors correctly\n",
    "    assert forecast.error is not None\n",
    "    assert len(forecast.periods) == 0\n",
    "    assert forecast.latitude == 37.7749\n",
    "\n",
    "# Test application layer with FAKE domain services  \n",
    "async def test_mcp_service_saves_forecasts():\n",
    "    # Fake provides working implementation with simplified behavior\n",
    "    class FakeWeatherService(WeatherService):\n",
    "        async def get_forecast(self, lat: float, lon: float) -> Forecast:\n",
    "            return Forecast(\n",
    "                periods=[WeatherPeriod(name=\"Test\", temperature=72.0, ...)],\n",
    "                error=None, latitude=lat, longitude=lon, retrieved_at=datetime.now()\n",
    "            )\n",
    "    \n",
    "    fake_weather_service = FakeWeatherService()\n",
    "    fake_repository = FakeWeatherRepository()\n",
    "    \n",
    "    mcp_service = WeatherMCPService(\n",
    "        mcp, fake_weather_service, fake_repository, fake_alert_repo\n",
    "    )\n",
    "    \n",
    "    # Test MCP orchestration without external dependencies\n",
    "    result = await mcp_service.get_forecast(37.7749, -122.4194)\n",
    "    \n",
    "    assert \"San Francisco\" in result\n",
    "    assert fake_repository.save_forecast_called\n",
    "```\n",
    "\n",
    "### Infrastructure Flexibility \n",
    "\n",
    "Need to switch from JSON file storage to Redis? Just implement the repository interface:\n",
    "\n",
    "```python\n",
    "class RedisWeatherForecastRepository(WeatherForecastRepository):\n",
    "    \"\"\"Redis-backed implementation of weather forecast repository.\"\"\"\n",
    "    \n",
    "    def __init__(self, redis_client):\n",
    "        self.redis = redis_client\n",
    "    \n",
    "    async def get_forecasts(self, latitude: float, longitude: float, **kwargs):\n",
    "        # Same interface, different storage mechanism\n",
    "        key = f\"forecasts:{latitude}:{longitude}\"\n",
    "        data = await self.redis.get(key)\n",
    "        return self._deserialize_forecasts(data) if data else []\n",
    "    \n",
    "    async def save_forecast(self, latitude: float, longitude: float, forecast: Forecast):\n",
    "        key = f\"forecasts:{latitude}:{longitude}\"\n",
    "        serialized = self._serialize_forecast(forecast)\n",
    "        await self.redis.lpush(key, serialized)\n",
    "        await self.redis.expire(key, 86400)  # 24 hour TTL\n",
    "```\n",
    "\n",
    "The domain and application layers remain completely unchanged - only the infrastructure implementation changes.\n",
    "\n",
    "### Enhanced LLM Understanding Through Domain Language\n",
    "\n",
    "Well-modeled domains with consistent terminology directly improve how LLMs reason about capabilities. Compare these two resource descriptions:\n",
    "\n",
    "```python\n",
    "# Poor domain modeling\n",
    "\"endpoint://data/fetch?type=weather&format=json&location={coords}&time=historical\"\n",
    "\n",
    "# Good domain modeling with ubiquitous language\n",
    "\"historical://alerts/{state} - Get historical weather alerts for a US state\"\n",
    "```\n",
    "\n",
    "The second immediately conveys to an LLM that:\n",
    "- This provides **historical** (not current) data\n",
    "- It's about weather **alerts** (not forecasts)  \n",
    "- It's organized by US **states** (not coordinates)\n",
    "- Parameter should be a state code (not lat/lon)\n",
    "\n",
    "This semantic clarity helps LLMs choose appropriate resources and construct valid requests.\n",
    "\n",
    "### Clear Architectural Boundaries\n",
    "\n",
    "The layered architecture provides clear separation of concerns that align with DDD principles:\n",
    "\n",
    "**Domain Layer** (`domain/`):\n",
    "- Contains weather-specific repository implementations that use infrastructure\n",
    "- `WeatherService`, `Forecast`, `WeatherAlert` domain models and services\n",
    "- Weather-specific business logic and data access patterns\n",
    "- Can import from infrastructure but stays focused on weather concepts\n",
    "\n",
    "**Application Layer** (`application/`):\n",
    "- Contains `WeatherMCPService` \n",
    "- Orchestrates domain objects to fulfill use cases\n",
    "- Handles MCP protocol translation\n",
    "- Coordinates between domain services and repositories\n",
    "\n",
    "**Infrastructure Layer** (`infrastructure/`):\n",
    "- Contains generic, reusable technical components\n",
    "- HTTP clients, file I/O, serialization patterns\n",
    "- `TimestampedCollectionRepository`, `JsonFileRepository` base classes\n",
    "- Can be used by any domain, contains no weather-specific logic\n",
    "\n",
    "This separation ensures changes in one layer don't cascade throughout the system, making the codebase easier to understand, modify, and maintain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1cbbc9",
   "metadata": {},
   "source": [
    "## Conclusion: Building AI Systems That Scale\n",
    "\n",
    "Domain-Driven Design and the Model Context Protocol form a powerful partnership for building maintainable AI integrations. By organizing our code around business domains rather than technical concerns, we create systems that are not only easier to understand and modify, but also provide LLMs with the clear, semantically rich interfaces they need to operate effectively.\n",
    "\n",
    "The patterns demonstrated here—ubiquitous language, bounded contexts, domain services, repositories, and application services—scale from simple weather lookups to complex enterprise integrations. As the AI ecosystem continues evolving, having these architectural foundations ensures your MCP servers can adapt and grow with changing requirements.\n",
    "\n",
    "### The Key Insight: Domain Language as the Bridge\n",
    "\n",
    "The most important insight from this exercise is that DDD's emphasis on domain modeling aligns perfectly with what makes LLMs effective: consistent terminology, well-defined capabilities, and semantic clarity. When we build systems that speak the language of the business domain, we create interfaces that both humans and AI can understand and use effectively.\n",
    "\n",
    "Consider the evolution from our original implementation:\n",
    "\n",
    "```python\n",
    "# Before: Technical jargon, mixed concerns\n",
    "@mcp.tool()\n",
    "async def get_alerts(state: str) -> str:\n",
    "    url = f\"{NWS_API_BASE}/alerts/active/area/{state}\"\n",
    "    data = await make_nws_request(url)\n",
    "    # ... URL construction, HTTP calls, JSON parsing all mixed together\n",
    "```\n",
    "\n",
    "To our domain-driven approach:\n",
    "\n",
    "```python\n",
    "# After: Clear domain language, separated concerns  \n",
    "async def get_alerts(self, state: str) -> str:\n",
    "    \"\"\"Get weather alerts for a US state.\"\"\"\n",
    "    alerts = await self.weather_service.get_alerts(state)\n",
    "    await self.weather_alert_repository.save_alerts(state, alerts)\n",
    "    return \"\\n---\\n\".join(alert.to_display_string() for alert in alerts)\n",
    "```\n",
    "\n",
    "The second version immediately communicates its intent: \"Get weather alerts, save them for historical analysis, and format them for presentation.\" The domain language makes both the purpose and the process clear.\n",
    "\n",
    "### Looking Forward: The Future of AI Integration\n",
    "\n",
    "As AI systems become more sophisticated, the importance of well-designed integration points will only grow. The ad-hoc, tightly-coupled approaches that might work for proof-of-concepts will become maintenance nightmares in production systems.\n",
    "\n",
    "The architectural patterns we've explored here—clear domain boundaries, dependency injection, repository abstractions, and protocol separation—provide a foundation that can evolve with changing requirements. Whether you're integrating with new AI models, switching data sources, or scaling to handle enterprise workloads, these patterns ensure your systems remain flexible and maintainable.\n",
    "\n",
    "Whether we are building your first MCP server or refactoring existing AI integrations, remember that the time invested in proper domain modeling and clean architecture pays dividends in maintainability, testability, and the overall quality of AI interactions with your systems. The future of AI integration lies not in ad-hoc connections, but in thoughtfully designed systems that bridge the gap between human intent and machine capability through shared domain understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e9c08f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
